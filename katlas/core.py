# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['param_PSPA_st', 'param_PSPA_y', 'param_CDDM', 'param_CDDM_upper', 'fetch_data', 'Data', 'CPTAC', 'get_unique_site',
           'convert_string', 'checker', 'STY2sty', 'cut_seq', 'extract_site_seq', 'raw2norm', 'get_one_kinase',
           'get_metaP', 'get_dict', 'multiply', 'sumup', 'predict_kinase', 'predict_kinase_df', 'get_pct', 'get_pct_df',
           'get_freq', 'query_gene']

# %% ../nbs/00_core.ipynb 4
import math, pandas as pd, numpy as np, seaborn as sns
from tqdm import tqdm
from fastcore.basics import partial
from scipy.stats import chi2
from typing import Callable
from functools import partial

# %% ../nbs/00_core.ipynb 7
def fetch_data(url):
    """
    Fetches the data from the given URL and returns a DataFrame
    """
    df = pd.read_parquet(url)
    if 'Unnamed: 0' in df.columns:
        df = df.rename(columns={'Unnamed: 0': 'kinase'})
    return df

# %% ../nbs/00_core.ipynb 8
class Data:
    
    "A class for fetching various datasets."
    #---------------------------kinase-------------------------------
    # kinase info
    KINASE_INFO_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/kinase_info.parquet"    
    @staticmethod
    def get_kinase_info():
        return fetch_data(Data.KINASE_INFO_URL)
    
    #---------------------------PSPA-------------------------------
    # PSPA tyrosine normalized data
    PSPA_TYR_NORM_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/PSPA/pspa_tyr_norm.parquet"
    @staticmethod
    def get_pspa_tyr_norm():
        "PSPA tyrosine kinase normalized data"
        return fetch_data(Data.PSPA_TYR_NORM_URL)
    
    
    # PSPA ST kinase normalized data
    PSPA_ST_NORM_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/PSPA/pspa_st_norm.parquet"
    @staticmethod
    def get_pspa_st_norm():
        "PSPA Ser/Thr kinase normalized data"
        return fetch_data(Data.PSPA_ST_NORM_URL)
    
    # scoring human all capital phosphoproteome via PSPA 
    PSPA_ST_PCT_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/PSPA/pspa_pct_st.parquet"
    # PSPA_TYR_PCT_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pspa_pct_tyr.parquet"
    @staticmethod
    def get_pspa_st_pct():
        return fetch_data(Data.PSPA_ST_PCT_URL)
    
    # @staticmethod
    # def get_pspa_tyr_pct():
    #     return fetch_data(Data.PSPA_TYR_PCT_URL)
    
    # PSPA number of random amino acids
    PSPA_NUM_RANDOM_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/PSPA/pspa_divide_num.csv"
    @staticmethod
    def get_num_dict():
        "PSPA number of random amino acids"
        num = pd.read_csv(Data.PSPA_NUM_RANDOM_URL)
        num_dict = num.set_index('kinase')['num_random_aa'].to_dict()

        return num_dict
    
    #---------------------------CDDM-------------------------------
        # Kinase substrate datasets
    KS_DATASET_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/CDDM/ks_datasets.parquet"
    @staticmethod
    def get_ks_dataset():
        df = fetch_data(Data.KS_DATASET_URL)
        #Convert the number in the column name into integer
        df.columns = [int(col) if col.lstrip('-').isdigit() else col for col in df.columns]
        return df
    
    # CDDM reference
    CDDM_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/CDDM/ks_main.parquet"
    @staticmethod
    def get_cddm():
        return fetch_data(Data.CDDM_URL)
    
    CDDM_UPPER_URL ="https://github.com/sky1ove/katlas/raw/main/dataset/CDDM/ks_main_upper.parquet"
    @staticmethod
    def get_cddm_upper():
        return fetch_data(Data.CDDM_UPPER_URL)
    
    # CDDM of other kinase with mutation
    CDDM_OTHERS_URL="https://github.com/sky1ove/katlas/raw/main/dataset/CDDM/ks_others.parquet"
    @staticmethod
    def get_cddm_others():
        return fetch_data(Data.CDDM_OTHERS_URL)
    
    CDDM_OTHERS_INFO_URL="https://github.com/sky1ove/katlas/raw/main/dataset/CDDM/ks_others_info.parquet"
    @staticmethod
    def get_cddm_others_info():
        return fetch_data(Data.CDDM_OTHERS_INFO_URL)
    
    
    #---------------------------CDDM+PSPA-------------------------------
    # Combined PSPA and CDDM
    COMBINE_URL =  "https://github.com/sky1ove/katlas/raw/main/dataset/combine_main.parquet"
    @staticmethod
    def get_combine():
        return fetch_data(Data.COMBINE_URL)
      

    #---------------------------Amino acid-------------------------------
    # Amino acid info
    AA_INFO_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/amino_acids/aa_info.parquet"
    AA_RDKIT_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/amino_acids/aa_rdkit.parquet"
    AA_MORGAN_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/amino_acids/aa_morgan.parquet"
    @staticmethod
    def get_aa_info():
        return fetch_data(Data.AA_INFO_URL)

    @staticmethod
    def get_aa_rdkit():
        return fetch_data(Data.AA_RDKIT_URL)
    
    @staticmethod
    def get_aa_morgan():
        return fetch_data(Data.AA_MORGAN_URL)
    

    #---------------------------phosphoproteomics dataset-------------------------------
    # For reference of linkedomicsKB, contains unique EnsemblProteinID+site, more sites
    CPTAC_KB_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/phosphosites/linkedOmicsKB_ref_pan.parquet"
    @staticmethod
    def get_cptac_ensembl_site():
        "For reference of linkedomicsKB, contains unique EnsemblProteinID+site"
        return fetch_data(Data.CPTAC_KB_URL)
    
    # From the above, but keep the unique site seq, with gene_site separated by |
    CPTAC_UNIQUE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/phosphosites/cptac_unique_site.parquet"
    @staticmethod
    def get_cptac_unique_site():
        "Unique site sequence of CPTAC"
        return fetch_data(Data.CPTAC_UNIQUE_URL)
    
    # for reference of linkedomics, contains unique Gene+site, fewer cases
    CPTAC_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/phosphosites/linkedOmics_ref_pan.parquet"
    @staticmethod
    def get_cptac_gene_site():
        "For reference of linkedomics, contains unique Gene+site, fewer cases than unique EnsemblID+site"
        return fetch_data(Data.CPTAC_URL)
    
    # from PhosphositePlus, contains Gene+site
    PSP_HUMAN_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/phosphosites/psp_human.parquet"
    @staticmethod
    def get_psp_human_site():
        "PhosphositePlus human, contains Gene+site"
        return fetch_data(Data.PSP_HUMAN_URL)
    
    # from ochoa et al. The functional landscape of the human phosphoproteome
    OCHOA_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/phosphosites/ochoa_site.parquet"
    @staticmethod
    def get_ochoa_site():
        "Ochoa et al. dataset"
        return fetch_data(Data.OCHOA_URL)
    
    # combine ochoa and PSP low throughput data
    COMBINE_PSP_OCHOA_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/phosphosites/combine_site_ochoa_psp.parquet"
    @staticmethod
    def get_combine_site_psp_ochoa():
        "Combined Ochoa and PhosphoSitePlus"
        df = fetch_data(Data.COMBINE_PSP_OCHOA_URL)
        
        #Convert the number in the column name into integer
        df.columns = [int(col) if col.lstrip('-').isdigit() else col for col in df.columns]
        return df
    

# %% ../nbs/00_core.ipynb 14
class CPTAC:
    
    "A class for fetching CPTAC phosphoproteomics data."
    
#     # Phosphoproteomics (Tumor)
#     HNSCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/HNSCC/HNSCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     GBM = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/GBM/GBM_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     COAD = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     CCRCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/CCRCC/CCRCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     LSCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LSCC/LSCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     BRCA = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/BRCA/BRCA_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     UCEC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/UCEC/UCEC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     LUAD = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LUAD/LUAD_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     PDAC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/PDAC/PDAC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     OV = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/OV/OV_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    
#     # Phosphoproteomics (Normal)
#     HNSCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/HNSCC/HNSCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     GBM_normal = None
#     COAD_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     CCRCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/CCRCC/CCRCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     LSCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LSCC/LSCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     BRCA_normal = None
#     UCEC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/UCEC/UCEC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     LUAD_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LUAD/LUAD_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     PDAC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/PDAC/PDAC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     OV_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/OV/OV_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    
#     # Ensemble ID gene mapping
#     HNSCC_ID = "https://zenodo.org/records/8196130/files/bcm-hnscc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     GBM_ID = "https://zenodo.org/records/8196130/files/bcm-gbm-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     COAD_ID = "https://zenodo.org/records/8196130/files/bcm-coad-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     CCRCC_ID = "https://zenodo.org/records/8196130/files/bcm-ccrcc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     LSCC_ID = "https://zenodo.org/records/8196130/files/bcm-lscc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     BRCA_ID = "https://zenodo.org/records/8196130/files/bcm-brca-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     UCEC_ID = "https://zenodo.org/records/8196130/files/bcm-ucec-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     LUAD_ID = "https://zenodo.org/records/8196130/files/bcm-luad-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     PDAC_ID = "https://zenodo.org/records/8196130/files/bcm-pdac-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     OV_ID = "https://zenodo.org/records/8196130/files/bcm-ov-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    
    
    @staticmethod
    def _fetch_data(cancer: str, # cancer type CPTAC
                    is_Tumor: bool=True, # tumor tissue or normal
                    is_KB: bool=False, # whether it is for LinkedOmicsKB or LinkedOmics
                   ):
        "Fetches the data from the given URL and returns a DataFrame"
        
        # URL of ID and data
        sample_type = "Tumor" if is_Tumor else "Normal"
        ID_URL = f"https://zenodo.org/records/8196130/files/bcm-{cancer.lower()}-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
        DATA_URL = f"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/{cancer.upper()}/{cancer.upper()}_phospho_site_abundance_log2_reference_intensity_normalized_{sample_type}.txt"

        # Load ID data
        ref = pd.read_csv(ID_URL, compression='gzip', sep='\t')[['protein','gene','gene_name']].drop_duplicates().reset_index(drop=True)
        
        # Load CPTAC phosphoproteomics data
        try:
            raw = pd.read_csv(DATA_URL, sep='\t')
        except Exception as e:
            print(f'{cancer} has {e}')
        else:
            info = pd.DataFrame({'gene':raw.idx.str.split('|').str[0],
                                 'site':raw.idx.str.split('|').str[2],
                                 'site_seq':raw.idx.str.split('|').str[3]})

            print(f'the {cancer} dataset length is: {info.shape[0]}')

            # Merge ensembl ID with gene name
            info = info.merge(ref,'left')
            print(f'after id mapping, the length is {info.shape[0]}')

            print(f'{info.gene_name.isna().sum()} sites does not have a mapped gene name')

            info['gene_site'] = info['gene_name'] + '_' + info['site']
            info['protein_site'] = info['protein'].str.split('.').str[0] + '_' + info['site']
            
            info = info.drop_duplicates(subset="protein_site" if is_KB else "gene_site").reset_index(drop=True)
            print(f'after removing duplicates of protein_site, the length is {info.shape[0]}')

            return info
    
    
    @staticmethod
    def list_cancer():
        "Get available CPTAC cancer type"
        return ['HNSCC','GBM','COAD','CCRCC','LSCC','BRCA','UCEC','LUAD','PDAC','OV']

    @staticmethod
    def get_id(cancer_type: str,
               is_Tumor: bool=True, # tumor tissue or normal
               is_KB: bool=False, # whether it is for LinkedOmicsKB or LinkedOmics
              ):
        "Get CPTAC phosphorylation sites information given a cancer type"
        assert cancer_type in CPTAC.list_cancer(), "cancer type is not included, check available cancer types from CPTAC.list_cancer()"
        return CPTAC._fetch_data(cancer_type,is_Tumor, is_KB)

# %% ../nbs/00_core.ipynb 20
def get_unique_site(df:pd.DataFrame = None,# dataframe that contains phosphorylation sites
                    seq_col: str='site_seq', # column name of site sequence
                    id_col: str='gene_site' # column name of site id
                   ):
    "Remove duplicates among phosphorylation sites; return df with new columns of acceptor and number of duplicates"
    
    unique = df.groupby(seq_col).agg(
        {id_col: lambda r: '|'.join(r.unique())} )
    unique['num_site'] = unique[id_col].str.split('|').apply(len) 
    unique = unique.reset_index()
    position = len(unique[seq_col][0])//2
    unique['acceptor'] = unique[seq_col].str[position]
    
    return unique

# %% ../nbs/00_core.ipynb 23
def convert_string(input_string:str):
    
    "Convert amino acids of lower case other than s,t,y to capital; convert rare amino acids to _"
    
    allowed_chars = 'PGACSTVILMFYWHKRQNDEsty'
    result = ""
    for char in input_string:
        # convert non-s/t/y to upper case
        result_char = char if char in ['s', 't', 'y'] else char.upper()
        # Replace with underscore if the character is not in the allowed set
        result += result_char if result_char in allowed_chars else '_'
    return result

# %% ../nbs/00_core.ipynb 26
def checker(input_string):
    "Check if the input string contains non-s/t/y at the middle position"
    acceptor = input_string[len(input_string)//2]
    assert acceptor.lower() in list('sty'),f"{input_string} has {acceptor} at position 0; need to have one of s,t and y"

def STY2sty(input_string: str):
    "Replace 'STY' with 'sty'"    
    return input_string.replace('S', 's').replace('T', 't').replace('Y', 'y')

# %% ../nbs/00_core.ipynb 28
def cut_seq(input_string: str, # site sequence
            min_position: int, # minimum position relative to its center
            max_position: int, # maximum position relative to its center
            ):
    
    "Extract sequence based on a range relative to its center position"
    
    # Find the center position of the string
    center_position = len(input_string) // 2

    # Calculate the start and end indices
    start_index = max(center_position + min_position, 0)  # Ensure start_index is not negative
    end_index = min(center_position + max_position + 1, len(input_string))  # Ensure end_index does not exceed string length

    # Extract and return the substring
    return input_string[start_index:end_index]

# %% ../nbs/00_core.ipynb 30
def extract_site_seq(df: pd.DataFrame, # dataframe that contains protein sequence
                     seq_col: str, # column name of protein sequence
                     position_col: str # column name of position 0
                    ):
    "Extract -7 to +7 site sequence from protein sequence"
    
    data = []
    for i, r in tqdm(df.iterrows(),total=len(df)):
        position = r[position_col] - 1
        start = position - 7
        end = position + 8

        # Extract the subsequence
        subseq = r[seq_col][max(0, start):min(len(r[seq_col]), end)]

        # Pad the subsequence if needed
        if start < 0:
            subseq = "_" * abs(start) + subseq
        if end > len(r[seq_col]):
            subseq = subseq + "_" * (end - len(r[seq_col]))

        data.append(subseq)
        
    return np.array(data)

# %% ../nbs/00_core.ipynb 35
def raw2norm(df: pd.DataFrame, # single kinase's df has position as index, and single amino acid as columns
             PDHK: bool=False, # whether this kinase belongs to PDHK family 
            ):
    
    "Normalize single ST kinase data"
    columns_to_exclude = ['S', 'T', 'C', 't', 'y']
    
    if PDHK:
        columns_to_exclude.append('Y')
        divisor = 16
    else:
        divisor = 17
    
    s = df.drop(columns=columns_to_exclude).sum(1)
    df2 = df.div(s, axis=0)
    df2.C = df2.C / (df2.C.median() * divisor)
    df2['S'] = df2.drop(columns=columns_to_exclude).median(1)
    df2['T'] = df2.drop(columns=columns_to_exclude).median(1)
    df2 = round(df2, 4)
    
    return df2

# %% ../nbs/00_core.ipynb 37
def get_one_kinase(df: pd.DataFrame, #stacked dataframe (paper's raw data)
                   kinase:str, # a specific kinase
                   normalize: bool=False, # normalize according to the paper; special for PDHK1/4
                   drop_s: bool= True # drop s if s is in column, specifically for PSPA raw data
                   ):
    "Obtain a specific kinase data from stacked dataframe"
    
    p = pd.DataFrame(df.loc[kinase],columns = [kinase]).reset_index().rename(columns={'index':'substrate'})
    p['position'] = p.substrate.str.extract('(-?\d+)')
    p['aa'] = p.substrate.str[-1]
    p.position = p.position.astype(int)
    pp = p.pivot(index='position', columns='aa', values=kinase)
    if drop_s:
        if 's' in pp.columns:
            pp = pp.drop(columns=['s'])

    if normalize:
        pp = raw2norm(pp, PDHK=True if kinase == 'PDHK1' or kinase == 'PDHK4' else False)
    return pp

# %% ../nbs/00_core.ipynb 52
def get_metaP(p_values):
    
    "Use Fisher's method to calculate a combined p value given a list of p values; this function also allows negative p values (negative correlation)"

    logs = [math.log(abs(p))*-1 if p<0 else math.log(abs(p)) for p in p_values]
    chi_square_stat = -2 * sum(logs)
    degrees_of_freedom = 2 * len(p_values)
    score = stats.chi2.sf(abs(chi_square_stat), degrees_of_freedom)*-1 if chi_square_stat<0 else chi2.sf(abs(chi_square_stat), degrees_of_freedom)

    return score

# %% ../nbs/00_core.ipynb 55
def get_dict(input_string:str, # phosphorylation site sequence
            ):
    
    "Get a dictionary of input string; no need for the star in the middle; make sure it is 15 or 10 length"

    center_index = len(input_string) // 2
    center_char = input_string[center_index]

    result = []

    for i, char in enumerate(input_string):
        position = i - center_index

        if char.isalpha():
            result.append(f"{position}{char}")

    return result

# %% ../nbs/00_core.ipynb 62
class multiply:
    "Include both Ser/Thr and Tyr kinases. "
    def __init__(self):
        
        self.num_dict = Data.get_num_dict()
        

    def func(self,values,kinase):
        
        self.divide = self.num_dict[kinase]

        # Using the logarithmic property: log(a*b) = log(a) + log(b)
        # Compute the sum of the logarithms of the values and the divide factor
        log_sum = np.sum(np.log2(values)) + (len(values) - 1) * np.log2(self.divide)

        return log_sum

# %% ../nbs/00_core.ipynb 66
def sumup(values, # list of values, possibilities of amino acids at certain positions
          kinase: str=None, # kinase name
         ):
    "Sum up the possibilities of the amino acids at each position in a phosphorylation site sequence"
    return sum(values)

# %% ../nbs/00_core.ipynb 69
def predict_kinase(input_string: str, # site sequence
                   ref: pd.DataFrame, # reference dataframe for scoring
                   func: Callable, # function to calculate score
                   to_lower: bool=False # convert capital STY to lower case
                   ):
    "Predict kinase given a phosphorylation site sequence"
    
    # check whether the middle position is sty
    checker(input_string)
    # convert rare amino acid to _ and lower case other than sty to capital
    input_string = convert_string(input_string)
    
    if to_lower:
        # convert STY in the sequence to lower case
        input_string = STY2sty(input_string)
    
    results=[]
    for kinase,row in tqdm(ref.iterrows(), total=ref.shape[0]):
        r_dict = row.to_dict() # To hash, PSSM dictionary for a single kinase
        
        pos_aa_name=get_dict(input_string)
        pos_aa_name = [key for key in pos_aa_name if key in ref.columns]
    
        pos_aa_val = [r_dict[key] for key in pos_aa_name]

        score = func(pos_aa_val,kinase)
        results.append(score)
    
    print(f'calculated string: {pos_aa_name}')

    out = pd.Series(results,index=ref.index).sort_values(ascending=False)
        
    return out.round(3)

# %% ../nbs/00_core.ipynb 71
# PSPA
param_PSPA_st = {'ref':Data.get_pspa_st_norm(), 'func':multiply().func} # Johnson et al. Nature official
# param2 = {'ref':Data.get_pspa_original(), 'func':multiply, 'to_lower': True} # convert all STY to sty in a sequence
param_PSPA_y = {'ref':Data.get_pspa_tyr_norm(), 'func':multiply().func}


# Kinase-substrate dataset, CDDM
param_CDDM = {'ref':Data.get_cddm(), 'func':sumup}
param_CDDM_upper = {'ref':Data.get_cddm_upper(), 'func':sumup} # specific for all uppercase

# %% ../nbs/00_core.ipynb 74
def predict_kinase_df(df:pd.DataFrame, # dataframe that contains site sequence
                      seq_col: str, # column name of site sequence
                      ref: pd.DataFrame, # reference df for scoring
                      func, # function to calculate score
                      to_lower: bool=False, # convert all S/T/Y to s/t/y in the sequence
                      ):
    "Predict kinase given a dataframe that contains phosphorylation site sequence and id"
    
    print('input dataframe has a length',df.shape[0])
    print('Preprocessing')
    
    # make a copy of df so that it does not change the original df
    df = df.copy()
    
    # check whether the middle position is sty
    df[seq_col].apply(checker)
    
    # convert rare amino acid to _ and lower case other than sty to capital
    df[seq_col] = df[seq_col].apply(convert_string)
    
    if to_lower:
        # convert STY in the sequence to lower case
        df[seq_col] = df[seq_col].apply(STY2sty)
        
    # cut sequence to fit for reference
    max_value = ref.columns.str[:-1].astype(int).max() # get minimum position from the reference
    min_value = ref.columns.str[:-1].astype(int).min() # get the max position
    df[seq_col] = df[seq_col].apply(partial(cut_seq,min_position=min_value, max_position=max_value))
    
    print('Finish preprocessing')
    
    results=[]
    num = list(set(ref.columns.str[:-1].astype(int)))
    num.sort()
    print(f'Calculating position: {num}')
    
    for kinase,row in tqdm(ref.iterrows(), total=ref.shape[0]):
        r_dict = row.to_dict() # To hash, PSSM dictionary for a single kinase
        result = []
        for input_string in df[seq_col]:
            pos_aa_name = get_dict(input_string)
            
            pos_aa_val = [r_dict[key] for key in pos_aa_name]
            
            score = func(pos_aa_val,kinase)
            result.append(score)

        results.append(result)
        
    out =pd.DataFrame(results,index=ref.index,columns=df.index).T
        
    return out

# %% ../nbs/00_core.ipynb 77
def get_pct(site,ref):
    
    "Replicate the precentile results from The Kinase Library."
    
    # As here we try to replicate the results, we use site.upper(); consider removing it for future version.
    score = predict_kinase(site.upper(),**param_PSPA_st)
    
    percentiles = {}
    for kinase in score.index: 
        # Get the values from `ref` for this kinase
        ref_values = ref[kinase].values
        # Calculate how many values in `ref` are less than the new score
        less = np.sum(ref_values < score[kinase])
        # Calculate how many values are equal to the new score
        equal = np.sum(ref_values == score[kinase])
        # Calculate the percentile rank
        percentile = (less + 0.5 * equal) / len(ref_values) * 100
        percentiles[kinase] = percentile
        
    pct = pd.Series(percentiles)
    final = pd.concat([score,pct],axis=1)
    final.columns=['log2(score)','percentile']
    return final

# %% ../nbs/00_core.ipynb 80
def get_pct_df(score_df, # output from predict_kinase_df 
               ref, # a reference df for percentile calculation
              ):
    
    "Replicate the precentile results from The Kinase Library."

    # Create an array to hold percentile ranks
    percentiles = np.zeros(score_df.shape)
    
    # Calculate percentiles for each column in a vectorized manner
    for i, kinase in tqdm(enumerate(score_df.columns),total=len(score_df.columns)):
        ref_values = np.sort(ref[kinase].values)
        
        # Use searchsorted to find indices where the scores would be inserted to maintain order
        indices = np.searchsorted(ref_values, score_df[kinase].values, side='right')
        
        # Calculate percentile ranks
        percentiles[:, i] = indices / len(ref_values) * 100

    # Convert the array to a DataFrame with appropriate indices and columns
    percentiles_df = pd.DataFrame(percentiles, index=score_df.index, columns=score_df.columns).astype(float).round(3)
    
    return percentiles_df

# %% ../nbs/00_core.ipynb 84
def get_freq(df_k: pd.DataFrame, # a dataframe for a single kinase that contains phosphorylation sequence splitted by their position
             aa_order = [i for i in 'PGACSTVILMFYWHKRQNDEsty'], # amino acid to include in the full matrix 
             aa_order_paper = [i for i in 'PGACSTVILMFYWHKRQNDEsty'], # amino acid to include in the partial matrix
             position = [i for i in range(-7,8)], # position to include in the full matrix
             position_paper = [-5,-4,-3,-2,-1,1,2,3,4] # position to include in the partial matrix
             ):
    
    "Get frequency matrix given a dataframe of phosphorylation sites for a single kinase"
    

    #Count frequency for each amino acid at each position
    melted_k = df_k.melt(
                    value_vars=[i for i in range(-7, 8)],
                    var_name='Position', 
                    value_name='aa')
    
    # Group by Position and Amino Acid and count occurrences
    grouped = melted_k.groupby(['Position', 'aa']).size().reset_index(name='Count')
    

    # Remove wired amino acid
    aa_include = [i for i in 'PGACSTVILMFYWHKRQNDEsty']
    grouped = grouped[grouped.aa.isin(aa_include)].reset_index(drop=True)
    
    # get pivot table
    pivot_k = grouped.pivot(index='aa', columns='Position', values='Count').fillna(0)
    
    # Get frequency by dividing the sum of each column
    freq_k = pivot_k/pivot_k.sum()

    
    # data from the kinase-substrate dataset, and format is Lew's paper's format
    paper = freq_k.reindex(index=aa_order_paper,columns=position_paper,fill_value=0)

    # full pivot data from kinase-substrate dataset
    full = freq_k.reindex(index=aa_order,columns=position, fill_value=0)

    
    return paper,full

# %% ../nbs/00_core.ipynb 88
def query_gene(df,gene):
    
    "Query gene in the phosphoproteomics dataset"
    
    # query gene in the dataframe
    df_gene = df[df.gene_site.str.contains(f'{gene}_')]
    
    # sort dataframe based on position
    sort_position = df_gene.gene_site.str.split('_').str[-1].str[1:].astype(int).sort_values().index
    df_gene = df_gene.loc[sort_position]
    
    return df_gene
