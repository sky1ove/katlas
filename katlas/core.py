# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['param1', 'param2', 'param3', 'param4', 'Data', 'CPTAC', 'get_unique_site', 'convert_string', 'checker', 'STY2sty',
           'cut_seq', 'extract_site_seq', 'raw2norm', 'get_one_kinase', 'unstack', 'get_metaP', 'get_dict', 'multiply',
           'sumup', 'predict_kinase', 'get_pct', 'predict_kinase_df', 'get_freq', 'query_gene']

# %% ../nbs/00_core.ipynb 4
import math, pandas as pd, numpy as np, seaborn as sns
from tqdm import tqdm
from fastcore.basics import partial
from scipy.stats import chi2
from typing import Callable
from functools import partial

# %% ../nbs/00_core.ipynb 7
class Data:
    """
    A class for fetching various datasets.
    """
    
    # Kinase info
    # KINASE_INFO_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/STkinase_info.parquet"
    KINASE_ALL_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/full_kinase_info.parquet"
    
    # ESM
    # KINASE_ESM_RAW_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/kinase_esm.parquet"
    # KINASE_ESM_PCA_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/kinase_esm_pca32.parquet"
    KINASE_ESM_FULL_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/kinase_esm_full.parquet"
    
    # T5
    # KINASE_T5_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/T5_xl_uniref50.parquet"
    KINASE_T5_FULL_BFD_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/T5_xl_bfd.parquet"
    KINASE_T5_FULL_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/T5_xl_uniref50_full.parquet"
    
    # Amino acid info
    AA_INFO_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/aa_info.parquet"
    AA_FEATURE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/aa_rdkit.parquet"
    AA_MORGAN_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/aa_morgan.parquet"
    
    # Paper raw data
    RAW_KINASE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/paper_raw.parquet"
    NORM_KINASE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/paper_norm.parquet"
    SCALE_KINASE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/paper_scale.parquet"
    
    
    # Unstacked target
    RAW_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_raw.parquet"
    
    # MEDIAN_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_median.parquet"
    # STANDARD_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_standard.parquet"
    # LOG_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_log.parquet"
    
    # Q85_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_q85.parquet"
    # Q85_UP40_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_q85_up40.parquet"
    
    # Stacked target
    # STANDARD_STACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pivot_standard.parquet"
    # LOG_STACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pivot_log.parquet"
    
    # Prepared dataset for training
    # DF_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/df_esm64_aa16.parquet"
    
    # Kinase substrate datasets
    KS_DATASET_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/ks_datasets.parquet"
    
    KS_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/ks_main.parquet"
    KS_UPPER_URL ="https://github.com/sky1ove/katlas/raw/main/dataset/ks_main_upper.parquet"
    KS_MAIN_INFO_URL="https://github.com/sky1ove/katlas/raw/main/dataset/ks_main_info.parquet"
    
    KS_OTHERS_URL="https://github.com/sky1ove/katlas/raw/main/dataset/ks_others.parquet"
    KS_OTHERS_INFO_URL="https://github.com/sky1ove/katlas/raw/main/dataset/ks_others_info.parquet"

    # scaled PSPA based on KS format
    PSPA_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pspa_main.parquet"
    PSPA_UPPER_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pspa_main_upper.parquet"
    # original pspa norm data with 0 position
    PSPA_ORIGINAL = "https://github.com/sky1ove/katlas/raw/main/dataset/pspa_original.parquet"
    
    # Combined PSPA and KS
    COMBINE_URL =  "https://github.com/sky1ove/katlas/raw/main/dataset/combine_main.parquet"
    COMBINE_UPPER_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/combine_main_upper.parquet"
    
    # reference databaase
    # For ref of linkedomicsKB, contains unique EnsemblProteinID+site
    CPTAC_KB_URL = "https://github.com/sky1ove/katlas/raw/main/phosphosites/linkedOmicsKB_ref_pan.parquet"
    # From the above, but keep the unique site seq, with gene_site separated by |
    CPTAC_UNIQUE_URL = "https://github.com/sky1ove/katlas/raw/main/phosphosites/cptac_unique_site.parquet"
    # for ref of linkedomics, contains unique Gene+site
    CPTAC_URL = "https://github.com/sky1ove/katlas/raw/main/phosphosites/linkedOmics_ref_pan.parquet"
    # from pplus, contains Gene+site
    PPLUS_HUMAN_URL = "https://github.com/sky1ove/katlas/raw/main/phosphosites/pplus_human.parquet"
    # from ochoa et al. The functional landscape of the human phosphoproteome
    OCHOA_URL = "https://github.com/sky1ove/katlas/raw/main/phosphosites/ochoa_site.parquet"
    # combined PPLUS low throughput and ochoa
    COMBINE_PPLUS_OCHOA_URL = "https://github.com/sky1ove/katlas/raw/main/phosphosites/combine_site_ochoa_pplus.parquet"
    
    OCHOA_PSPA_SCORE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/ochoa_pspa_score.parquet"

    
    @staticmethod
    def _fetch_data(url):
        """
        Fetches the data from the given URL and returns a DataFrame
        """
        df = pd.read_parquet(url)
        if 'Unnamed: 0' in df.columns:
            df = df.rename(columns={'Unnamed: 0': 'kinase'})
        return df
    
    @staticmethod
    def get_ochoa_score():
        return Data._fetch_data(Data.OCHOA_PSPA_SCORE_URL)
    

    @staticmethod
    def get_pspa_raw():
        return Data._fetch_data(Data.RAW_KINASE_URL)
    
    @staticmethod
    def get_pspa_norm():
        return Data._fetch_data(Data.NORM_KINASE_URL)
    
    
    @staticmethod
    def get_pspa_scale():
        return Data._fetch_data(Data.SCALE_KINASE_URL)

    # @staticmethod
    # def get_kinase_info():
    #     return Data._fetch_data(Data.KINASE_INFO_URL)

    @staticmethod
    def get_kinase_info_full():
        return Data._fetch_data(Data.KINASE_ALL_URL)
    
    # @staticmethod
    # def get_esm():
    #     return Data._fetch_data(Data.KINASE_ESM_RAW_URL)

    @staticmethod
    def get_esm_full():
        return Data._fetch_data(Data.KINASE_ESM_FULL_URL)

    # @staticmethod
    # def get_t5():
    #     return Data._fetch_data(Data.KINASE_T5_URL)

    @staticmethod
    def get_t5_full():
        return Data._fetch_data(Data.KINASE_T5_FULL_URL)
    
    @staticmethod
    def get_t5_bfd_full():
        return Data._fetch_data(Data.KINASE_T5_FULL_BFD_URL)

    @staticmethod
    def get_aa_info():
        return Data._fetch_data(Data.AA_INFO_URL)

    @staticmethod
    def get_aa_feature():
        return Data._fetch_data(Data.AA_FEATURE_URL)

#     @staticmethod
#     def get_unstack_standard():
#         return Data._fetch_data(Data.STANDARD_UNSTACK_URL)

#     @staticmethod
#     def get_unstack_log():
#         return Data._fetch_data(Data.LOG_UNSTACK_URL)

#     @staticmethod
#     def get_unstack_med():
#         return Data._fetch_data(Data.MEDIAN_UNSTACK_URL)

#     @staticmethod
#     def get_unstack_raw():
#         return Data._fetch_data(Data.RAW_UNSTACK_URL)

#     @staticmethod
#     def get_unstack_q85():
#         return Data._fetch_data(Data.Q85_UNSTACK_URL)

#     @staticmethod
#     def get_unstack_q85_up40():
#         return Data._fetch_data(Data.Q85_UP40_UNSTACK_URL)

#     @staticmethod
#     def get_log_stack():
#         return Data._fetch_data(Data.LOG_STACK_URL)

#     @staticmethod
#     def get_standard_stack():
#         return Data._fetch_data(Data.STANDARD_STACK_URL)

#     @staticmethod
#     def get_prepared_data():
#         return Data._fetch_data(Data.DF_URL)
    
    @staticmethod
    def get_ks_dataset():
        df = Data._fetch_data(Data.KS_DATASET_URL)
        #Convert the number in the column name into integer
        df.columns = [int(col) if col.lstrip('-').isdigit() else col for col in df.columns]
        return df
        
    @staticmethod
    def get_ks():
        return Data._fetch_data(Data.KS_URL)
    
    @staticmethod
    def get_ks_upper():
        return Data._fetch_data(Data.KS_UPPER_URL)
    
    @staticmethod
    def get_ks_main_info():
        return Data._fetch_data(Data.KS_MAIN_INFO_URL)
    
    @staticmethod
    def get_ks_others():
        return Data._fetch_data(Data.KS_OTHERS_URL)
    
    @staticmethod
    def get_ks_others_info():
        return Data._fetch_data(Data.KS_OTHERS_INFO_URL)
    
    @staticmethod
    def get_pspa_upper():
        return Data._fetch_data(Data.PSPA_UPPER_URL)
    
    @staticmethod
    def get_pspa():
        return Data._fetch_data(Data.PSPA_URL)
    
    @staticmethod
    def get_pspa_original():
        return Data._fetch_data(Data.PSPA_ORIGINAL)
    
    @staticmethod
    def get_combine_upper():
        return Data._fetch_data(Data.COMBINE_UPPER_URL)
    
    @staticmethod
    def get_combine():
        return Data._fetch_data(Data.COMBINE_URL)
    
    
    # unique gene+site, but less cases
    @staticmethod
    def get_cptac_gene_site():
        return Data._fetch_data(Data.CPTAC_URL)
    
    # ensemblID + site, with more sites
    @staticmethod
    def get_cptac_ensembl_site():
        return Data._fetch_data(Data.CPTAC_KB_URL)
    
    @staticmethod
    def get_pplus_human_site():
        return Data._fetch_data(Data.PPLUS_HUMAN_URL)
    
    @staticmethod
    def get_ochoa_site():
        return Data._fetch_data(Data.OCHOA_URL)
    
    @staticmethod
    def get_cptac_unique_site():
        return Data._fetch_data(Data.CPTAC_UNIQUE_URL)
    
    @staticmethod
    def get_combine_site_pplus_ochoa():
        
        df = Data._fetch_data(Data.COMBINE_PPLUS_OCHOA_URL)
        
        #Convert the number in the column name into integer
        df.columns = [int(col) if col.lstrip('-').isdigit() else col for col in df.columns]
        return df

# %% ../nbs/00_core.ipynb 15
class CPTAC:
    
    "A class for fetching CPTAC phosphoproteomics data."
    
#     # Phosphoproteomics (Tumor)
#     HNSCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/HNSCC/HNSCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     GBM = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/GBM/GBM_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     COAD = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     CCRCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/CCRCC/CCRCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     LSCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LSCC/LSCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     BRCA = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/BRCA/BRCA_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     UCEC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/UCEC/UCEC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     LUAD = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LUAD/LUAD_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     PDAC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/PDAC/PDAC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
#     OV = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/OV/OV_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    
#     # Phosphoproteomics (Normal)
#     HNSCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/HNSCC/HNSCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     GBM_normal = None
#     COAD_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     CCRCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/CCRCC/CCRCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     LSCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LSCC/LSCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     BRCA_normal = None
#     UCEC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/UCEC/UCEC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     LUAD_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LUAD/LUAD_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     PDAC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/PDAC/PDAC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
#     OV_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/OV/OV_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    
#     # Ensemble ID gene mapping
#     HNSCC_ID = "https://zenodo.org/records/8196130/files/bcm-hnscc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     GBM_ID = "https://zenodo.org/records/8196130/files/bcm-gbm-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     COAD_ID = "https://zenodo.org/records/8196130/files/bcm-coad-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     CCRCC_ID = "https://zenodo.org/records/8196130/files/bcm-ccrcc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     LSCC_ID = "https://zenodo.org/records/8196130/files/bcm-lscc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     BRCA_ID = "https://zenodo.org/records/8196130/files/bcm-brca-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     UCEC_ID = "https://zenodo.org/records/8196130/files/bcm-ucec-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     LUAD_ID = "https://zenodo.org/records/8196130/files/bcm-luad-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     PDAC_ID = "https://zenodo.org/records/8196130/files/bcm-pdac-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
#     OV_ID = "https://zenodo.org/records/8196130/files/bcm-ov-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    
    
    @staticmethod
    def _fetch_data(cancer: str, # cancer type CPTAC
                    is_Tumor: bool=True, # tumor tissue or normal
                    is_KB: bool=False, # whether it is for LinkedOmicsKB or LinkedOmics
                   ):
        "Fetches the data from the given URL and returns a DataFrame"
        
        # URL of ID and data
        sample_type = "Tumor" if is_Tumor else "Normal"
        ID_URL = f"https://zenodo.org/records/8196130/files/bcm-{cancer.lower()}-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
        DATA_URL = f"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/{cancer.upper()}/{cancer.upper()}_phospho_site_abundance_log2_reference_intensity_normalized_{sample_type}.txt"

        # Load ID data
        ref = pd.read_csv(ID_URL, compression='gzip', sep='\t')[['protein','gene','gene_name']].drop_duplicates().reset_index(drop=True)
        
        # Load CPTAC phosphoproteomics data
        try:
            raw = pd.read_csv(DATA_URL, sep='\t')
        except Exception as e:
            print(f'{cancer} has {e}')
        else:
            info = pd.DataFrame({'gene':raw.idx.str.split('|').str[0],
                                 'site':raw.idx.str.split('|').str[2],
                                 'site_seq':raw.idx.str.split('|').str[3]})

            print(f'the {cancer} dataset length is: {info.shape[0]}')

            # Merge ensembl ID with gene name
            info = info.merge(ref,'left')
            print(f'after id mapping, the length is {info.shape[0]}')

            print(f'{info.gene_name.isna().sum()} sites does not have a mapped gene name')

            info['gene_site'] = info['gene_name'] + '_' + info['site']
            info['protein_site'] = info['protein'].str.split('.').str[0] + '_' + info['site']
            
            info = info.drop_duplicates(subset="protein_site" if is_KB else "gene_site").reset_index(drop=True)
            print(f'after removing duplicates of protein_site, the length is {info.shape[0]}')

            return info
    
    
    @staticmethod
    def list_cancer():
        "Get available CPTAC cancer type"
        return ['HNSCC','GBM','COAD','CCRCC','LSCC','BRCA','UCEC','LUAD','PDAC','OV']

    @staticmethod
    def get_id(cancer_type: str,
               is_Tumor: bool=True, # tumor tissue or normal
               is_KB: bool=False, # whether it is for LinkedOmicsKB or LinkedOmics
              ):
        "Get CPTAC phosphorylation sites information given a cancer type"
        assert cancer_type in CPTAC.list_cancer(), "cancer type is not included, check available cancer types from CPTAC.list_cancer()"
        return CPTAC._fetch_data(cancer_type,is_Tumor, is_KB)

# %% ../nbs/00_core.ipynb 21
def get_unique_site(df:pd.DataFrame = None,# dataframe that contains phosphorylation sites
                    seq_col: str='site_seq', # column name of site sequence
                    id_col: str='gene_site' # column name of site id
                   ):
    "Remove duplicates among phosphorylation sites; return df with new columns of acceptor and number of duplicates"
    
    unique = df.groupby(seq_col).agg(
        {id_col: lambda r: '|'.join(r.unique())} )
    unique['num_site'] = unique[id_col].str.split('|').apply(len) 
    unique = unique.reset_index()
    position = len(unique[seq_col][0])//2
    unique['acceptor'] = unique[seq_col].str[position]
    
    return unique

# %% ../nbs/00_core.ipynb 24
def convert_string(input_string:str):
    
    "Convert amino acids of lower case other than s,t,y to capital; convert rare amino acids to _"
    
    allowed_chars = 'PGACSTVILMFYWHKRQNDEsty'
    result = ""
    for char in input_string:
        # convert non-s/t/y to upper case
        result_char = char if char in ['s', 't', 'y'] else char.upper()
        # Replace with underscore if the character is not in the allowed set
        result += result_char if result_char in allowed_chars else '_'
    return result

# %% ../nbs/00_core.ipynb 27
def checker(input_string):
    "Check if the input string contains non-s/t/y at the middle position"
    acceptor = input_string[len(input_string)//2]
    assert acceptor.lower() in list('sty'),f"{input_string} has {acceptor} at position 0; need to have one of s,t and y"

def STY2sty(input_string: str):
    "Replace 'STY' with 'sty'"    
    return input_string.replace('S', 's').replace('T', 't').replace('Y', 'y')

# %% ../nbs/00_core.ipynb 29
def cut_seq(input_string: str, # site sequence
            min_position: int, # minimum position relative to its center
            max_position: int, # maximum position relative to its center
            ):
    
    "Extract sequence based on a range relative to its center position"
    
    # Find the center position of the string
    center_position = len(input_string) // 2

    # Calculate the start and end indices
    start_index = max(center_position + min_position, 0)  # Ensure start_index is not negative
    end_index = min(center_position + max_position + 1, len(input_string))  # Ensure end_index does not exceed string length

    # Extract and return the substring
    return input_string[start_index:end_index]

# %% ../nbs/00_core.ipynb 32
def extract_site_seq(df: pd.DataFrame, # dataframe that contains protein sequence
                     seq_col: str, # column name of protein sequence
                     position_col: str # column name of position 0
                    ):
    "Based on position 0, extract -7 to +7 site sequence from protein sequence"
    
    data = []
    for i, r in tqdm(df.iterrows(),total=len(df)):
        position = r[position_col] - 1
        start = position - 7
        end = position + 8

        # Extract the subsequence
        subseq = r[seq_col][max(0, start):min(len(r[seq_col]), end)]

        # Pad the subsequence if needed
        if start < 0:
            subseq = "_" * abs(start) + subseq
        if end > len(r[seq_col]):
            subseq = subseq + "_" * (end - len(r[seq_col]))

        data.append(subseq)
        
    return np.array(data)

# %% ../nbs/00_core.ipynb 36
def raw2norm(df: pd.DataFrame, # single kinase's df has position as index, and single amino acid as columns
             PDHK: bool=False, # whether this kinase belongs to PDHK family 
            ):
    
    "Normalize single kinase data"
    columns_to_exclude = ['S', 'T', 'C', 't', 'y']
    
    if PDHK:
        columns_to_exclude.append('Y')
        divisor = 16
    else:
        divisor = 17
    
    s = df.drop(columns=columns_to_exclude).sum(1)
    df2 = df.div(s, axis=0)
    df2.C = df2.C / (df2.C.median() * divisor)
    df2['S'] = df2.drop(columns=columns_to_exclude).median(1)
    df2['T'] = df2.drop(columns=columns_to_exclude).median(1)
    df2 = round(df2, 4)
    
    return df2

# %% ../nbs/00_core.ipynb 38
def get_one_kinase(df: pd.DataFrame, #stacked dataframe (paper's raw data)
                   kinase:str, # a specific kinase
                   normalize: bool=False, # normalize according to the paper; special for PDHK1/4
                   drop_s: bool= True # drop s if s is in column, specifically for PSPA raw data
                   ):
    "Obtain a specific kinase data from stacked dataframe"
    
    p = pd.DataFrame(df.loc[kinase],columns = [kinase]).reset_index().rename(columns={'index':'substrate'})
    p['position'] = p.substrate.str.extract('(-?\d+)')
    p['aa'] = p.substrate.str[-1]
    p.position = p.position.astype(int)
    pp = p.pivot(index='position', columns='aa', values=kinase)
    if drop_s:
        if 's' in pp.columns:
            pp = pp.drop(columns=['s'])

    if normalize:
        pp = raw2norm(pp, PDHK=True if kinase == 'PDHK1' or kinase == 'PDHK4' else False)
    return pp

# %% ../nbs/00_core.ipynb 49
def unstack(df: pd.DataFrame, # stacked dataframe
            name:str='target' # column name of values 
           ):
    "Unstack and split PSPA data"
    
    # Unstack
    df = df.unstack().reset_index(name = name)
    
    # Rename column
    df = df.rename(columns = {'level_0':'substrate'})
    
    # Reorder column
    df = df[['kinase','substrate',name]]
    
    # Deal with some warning issue
    df = df.copy()
    
    # Divide substrate info into position and aa
    df['position'] = df.substrate.str.extract('(-?\d+)')
    df['aa'] = df.substrate.str[-1]
    
    # Remove 's' as it is a duplicate of 't'
    df = df[df['aa'] != 's'].reset_index(drop=True)
    
    return df

# %% ../nbs/00_core.ipynb 52
def get_metaP(p_values):
    
    "Use Fisher's method to calculate a combined p value given a list of p values; this function also allows negative p values (negative correlation)"

    logs = [math.log(abs(p))*-1 if p<0 else math.log(abs(p)) for p in p_values]
    chi_square_stat = -2 * sum(logs)
    degrees_of_freedom = 2 * len(p_values)
    score = stats.chi2.sf(abs(chi_square_stat), degrees_of_freedom)*-1 if chi_square_stat<0 else chi2.sf(abs(chi_square_stat), degrees_of_freedom)

    return score

# %% ../nbs/00_core.ipynb 55
def get_dict(input_string:str, # phosphorylation site sequence
            ):
    
    "Get a dictionary of input string; no need for the star in the middle; make sure it is 15 or 10 length"

    center_index = len(input_string) // 2
    center_char = input_string[center_index]

    result = []

    for i, char in enumerate(input_string):
        position = i - center_index

        if char.isalpha():
            result.append(f"{position}{char}")

    return result

# %% ../nbs/00_core.ipynb 58
def multiply(values, # list of values, possibilities of amino acids at certain positions
             kinase:str, # kinase name
            ):
    
    "Multiply the possibilities of the amino acids at each position in a phosphorylation site"
    
    divide = 16 if 'PDHK' in kinase else 17

    # Using the logarithmic property: log(a*b) = log(a) + log(b)
    # Compute the sum of the logarithms of the values and the divide factor
    log_sum = np.sum(np.log2(values)) + (len(values) - 1) * np.log2(divide)

    return log_sum

# %% ../nbs/00_core.ipynb 62
def sumup(values, # list of values, possibilities of amino acids at certain positions
          kinase: str=None, # kinase name
         ):
    "Sum up the possibilities of the amino acids at each position in a phosphorylation site sequence"
    return sum(values)

# %% ../nbs/00_core.ipynb 64
def predict_kinase(input_string: str, # site sequence
                   ref: pd.DataFrame, # reference dataframe for scoring
                   func: Callable, # function to calculate score
                   to_lower: bool=True # convert capital STY to lower case
                   ):
    "Predict kinase given a phosphorylation site sequence"
    
    # check whether the middle position is sty
    checker(input_string)
    # convert rare amino acid to _ and lower case other than sty to capital
    input_string = convert_string(input_string)
    
    if to_lower:
        # convert STY in the sequence to lower case
        input_string = STY2sty(input_string)
    
    results=[]
    for kinase,row in tqdm(ref.iterrows(), total=ref.shape[0]):
        r_dict = row.to_dict() # To hash, PSSM dictionary for a single kinase
        
        pos_aa_name=get_dict(input_string)
        pos_aa_name = [key for key in pos_aa_name if key in ref.columns]
    
        pos_aa_val = [r_dict[key] for key in pos_aa_name]

        score = func(pos_aa_val,kinase)
        results.append(score)
    
    print(f'calculated string: {pos_aa_name}')

    out = pd.Series(results,index=ref.index).sort_values(ascending=False)
        
    return out.round(3)

# %% ../nbs/00_core.ipynb 66
# PSPA
param1 = {'ref':Data.get_pspa_original(), 'func':multiply, 'to_lower': False} # Johnson et al. Nature official
param2 = {'ref':Data.get_pspa_original(), 'func':multiply, 'to_lower': True} # convert all STY to sty in a sequence

# Kinase-substrate dataset
param3 = {'ref':Data.get_ks(), 'func':sumup, 'to_lower': False}
param4 = {'ref':Data.get_ks_upper(), 'func':sumup, 'to_lower': False} # specific for all uppercase

# %% ../nbs/00_core.ipynb 69
def get_pct(site,ref):
    
    score = predict_kinase(site.upper(),**param1)
    
    percentiles = {}
    for kinase in score.index: 
        # Get the values from `ref` for this kinase
        ref_values = ref[kinase].values
        # Calculate how many values in `ref` are less than the new score
        less = np.sum(ref_values < score[kinase])
        # Calculate how many values are equal to the new score
        equal = np.sum(ref_values == score[kinase])
        # Calculate the percentile rank
        percentile = (less + 0.5 * equal) / len(ref_values) * 100
        percentiles[kinase] = percentile
        
    pct = pd.Series(percentiles)
    final = pd.concat([score,pct],axis=1)
    final.columns=['log2(score)','percentile']
    return final

# %% ../nbs/00_core.ipynb 71
def predict_kinase_df(df:pd.DataFrame, # dataframe that contains site sequence
                      seq_col: str, # column name of site sequence
                      ref: pd.DataFrame, # reference df for scoring
                      func, # function to calculate score
                      to_lower: bool
                      ):
    "Predict kinase given a dataframe that contains phosphorylation site sequence and id"
    
    print('input dataframe has a length',df.shape[0])
    print('Preprocessing')
    
    # make a copy of df so that it does not change the original df
    df = df.copy()
    
    # check whether the middle position is sty
    df[seq_col].apply(checker)
    
    # convert rare amino acid to _ and lower case other than sty to capital
    df[seq_col] = df[seq_col].apply(convert_string)
    
    if to_lower:
        # convert STY in the sequence to lower case
        df[seq_col] = df[seq_col].apply(STY2sty)
        
    # cut sequence to fit for reference
    max_value = ref.columns.str[:-1].astype(int).max() # get minimum position from the reference
    min_value = ref.columns.str[:-1].astype(int).min() # get the max position
    df[seq_col] = df[seq_col].apply(partial(cut_seq,min_position=min_value, max_position=max_value))
    
    print('Finish preprocessing')
    
    results=[]
    num = list(set(ref.columns.str[:-1].astype(int)))
    num.sort()
    print(f'Calculating position: {num}')
    
    for kinase,row in tqdm(ref.iterrows(), total=ref.shape[0]):
        r_dict = row.to_dict() # To hash, PSSM dictionary for a single kinase
        result = []
        for input_string in df[seq_col]:
            pos_aa_name = get_dict(input_string)
            
            pos_aa_val = [r_dict[key] for key in pos_aa_name]
            
            score = func(pos_aa_val,kinase)
            result.append(score)

        results.append(result)
        
    out =pd.DataFrame(results,index=ref.index,columns=df.index).T
        
    return out

# %% ../nbs/00_core.ipynb 78
def get_freq(df_k: pd.DataFrame, # a dataframe for a single kinase that contains phosphorylation sequence splitted by their position
             aa_order = [i for i in 'PGACSTVILMFYWHKRQNDEsty'], # amino acid to include in the full matrix 
             aa_order_paper = [i for i in 'PGACSTVILMFYWHKRQNDEsty'], # amino acid to include in the partial matrix
             position = [i for i in range(-7,8)], # position to include in the full matrix
             position_paper = [-5,-4,-3,-2,-1,1,2,3,4] # position to include in the partial matrix
             ):
    
    "Get frequency matrix given a dataframe of phosphorylation sites for a single kinase"
    

    #Count frequency for each amino acid at each position
    melted_k = df_k.melt(
                    value_vars=[i for i in range(-7, 8)],
                    var_name='Position', 
                    value_name='aa')
    
    # Group by Position and Amino Acid and count occurrences
    grouped = melted_k.groupby(['Position', 'aa']).size().reset_index(name='Count')
    

    # Remove wired amino acid
    aa_include = [i for i in 'PGACSTVILMFYWHKRQNDEsty']
    grouped = grouped[grouped.aa.isin(aa_include)].reset_index(drop=True)
    
    # get pivot table
    pivot_k = grouped.pivot(index='aa', columns='Position', values='Count').fillna(0)
    
    # Get frequency by dividing the sum of each column
    freq_k = pivot_k/pivot_k.sum()

    
    # data from the kinase-substrate dataset, and format is Lew's paper's format
    paper = freq_k.reindex(index=aa_order_paper,columns=position_paper,fill_value=0)

    # full pivot data from kinase-substrate dataset
    full = freq_k.reindex(index=aa_order,columns=position, fill_value=0)

    
    return paper,full

# %% ../nbs/00_core.ipynb 81
def query_gene(df,gene):
    
    "Query gene in the phosphoproteomics dataset"
    
    # query gene in the dataframe
    df_gene = df[df.gene_site.str.contains(f'{gene}_')]
    
    # sort dataframe based on position
    sort_position = df_gene.gene_site.str.split('_').str[-1].str[1:].astype(int).sort_values().index
    df_gene = df_gene.loc[sort_position]
    
    return df_gene
