# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['Data', 'CPTAC', 'extract_site_seq', 'raw2norm', 'get_one_kinase', 'unstack', 'get_dict', 'multiply', 'sumup',
           'predict_kinase', 'predict_kinase_df', 'agg_seq', 'get_freq']

# %% ../nbs/00_core.ipynb 3
import pandas as pd
import numpy as np
import seaborn as sns
from fastcore.basics import partial
from tqdm import tqdm

# from fastbook import *

# %% ../nbs/00_core.ipynb 7
class Data:
    """
    A class for fetching various datasets.
    """
    
    # Kinase info
    KINASE_INFO_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/STkinase_info.parquet"
    KINASE_ALL_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/full_kinase_info.parquet"
    
    # ESM
    KINASE_ESM_RAW_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/kinase_esm.parquet"
    KINASE_ESM_PCA_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/kinase_esm_pca32.parquet"
    KINASE_ESM_FULL_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/kinase_esm_full.parquet"
    
    # T5
    KINASE_T5_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/T5_xl_uniref50.parquet"
    KINASE_T5_FULL_BFD_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/T5_xl_bfd.parquet"
    KINASE_T5_FULL_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/T5_xl_uniref50_full.parquet"
    
    # Amino acid info
    AA_INFO_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/aa_info.parquet"
    AA_FEATURE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/aa_rdkit.parquet"
    AA_MORGAN_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/aa_morgan.parquet"
    
    # Paper raw data
    RAW_KINASE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/paper_raw.parquet"
    NORM_KINASE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/paper_norm.parquet"
    SCALE_KINASE_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/paper_scale.parquet"
    
    
    # Unstacked target
    RAW_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_raw.parquet"
    
    MEDIAN_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_median.parquet"
    STANDARD_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_standard.parquet"
    LOG_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_log.parquet"
    
    Q85_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_q85.parquet"
    Q85_UP40_UNSTACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/unstack_q85_up40.parquet"
    
    # Stacked target
    STANDARD_STACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pivot_standard.parquet"
    LOG_STACK_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pivot_log.parquet"
    
    # Prepared dataset
    DF_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/df_esm64_aa16.parquet"
    
    # Kinase substrate datasets
    KS_DATASET_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/ks_datasets.parquet"
    
    KS_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/ks_main.parquet"
    KS_UPPER_URL ="https://github.com/sky1ove/katlas/raw/main/dataset/ks_main_upper.parquet"
    KS_MAIN_INFO_URL="https://github.com/sky1ove/katlas/raw/main/dataset/ks_main_info.parquet"
    
    KS_OTHERS_URL="https://github.com/sky1ove/katlas/raw/main/dataset/ks_others.parquet"
    KS_OTHERS_INFO_URL="https://github.com/sky1ove/katlas/raw/main/dataset/ks_others_info.parquet"

    # scaled PSPA based on KS format
    PSPA_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pspa_main.parquet"
    PSPA_UPPER_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/pspa_main_upper.parquet"
    # original pspa norm data with 0 position
    PSPA_ORIGINAL = "https://github.com/sky1ove/katlas/raw/main/dataset/pspa_original.parquet"
    
    # Combined PSPA and KS
    COMBINE_URL =  "https://github.com/sky1ove/katlas/raw/main/dataset/combine_main.parquet"
    COMBINE_UPPER_URL = "https://github.com/sky1ove/katlas/raw/main/dataset/combine_main_upper.parquet"
    
    # reference databaase
    # For ref of linkedomicsKB, contains unique EnsemblProteinID+site
    CPTAC_KB_URL = "https://github.com/sky1ove/katlas/raw/main/database/linkedOmicsKB_ref_pan.parquet"
    # From the above, but keep the unique site seq, with gene_site separated by |
    CPTAC_UNIQUE_URL = "https://github.com/sky1ove/katlas/raw/main/database/cptac_unique_site.parquet"
    # for ref of linkedomics, contains unique Gene+site
    CPTAC_URL = "https://github.com/sky1ove/katlas/raw/main/database/linkedOmics_ref_pan.parquet"
    # from pplus, contains Gene+site
    PPLUS_HUMAN_URL = "https://github.com/sky1ove/katlas/raw/main/database/pplus_human.parquet"
    # from ochoa et al. The functional landscape of the human phosphoproteome
    OCHOA_URL = "https://github.com/sky1ove/katlas/raw/main/database/ochoa_site.parquet"
    
    
    
    def __init__(self):
        pass
    
    @staticmethod
    def _fetch_data(url):
        """
        Fetches the data from the given URL and returns a DataFrame
        """
        df = pd.read_parquet(url)
        if 'Unnamed: 0' in df.columns:
            df = df.rename(columns={'Unnamed: 0': 'kinase'})
        return df
    

    @staticmethod
    def get_stack_raw():
        return Data._fetch_data(Data.RAW_KINASE_URL)
    
    @staticmethod
    def get_stack_norm():
        return Data._fetch_data(Data.NORM_KINASE_URL)
    
    
    @staticmethod
    def get_stack_scale():
        return Data._fetch_data(Data.SCALE_KINASE_URL)

    @staticmethod
    def get_kinase_info():
        return Data._fetch_data(Data.KINASE_INFO_URL)

    @staticmethod
    def get_kinase_info_full():
        return Data._fetch_data(Data.KINASE_ALL_URL)
    
    @staticmethod
    def get_esm():
        return Data._fetch_data(Data.KINASE_ESM_RAW_URL)

    @staticmethod
    def get_esm_full():
        return Data._fetch_data(Data.KINASE_ESM_FULL_URL)

    @staticmethod
    def get_t5():
        return Data._fetch_data(Data.KINASE_T5_URL)

    @staticmethod
    def get_t5_full():
        return Data._fetch_data(Data.KINASE_T5_FULL_URL)
    
    @staticmethod
    def get_t5_bfd_full():
        return Data._fetch_data(Data.KINASE_T5_FULL_BFD_URL)
    

    @staticmethod
    def get_aa_info():
        return Data._fetch_data(Data.AA_INFO_URL)

    @staticmethod
    def get_aa_feature():
        return Data._fetch_data(Data.AA_FEATURE_URL)

    @staticmethod
    def get_unstack_standard():
        return Data._fetch_data(Data.STANDARD_UNSTACK_URL)

    @staticmethod
    def get_unstack_log():
        return Data._fetch_data(Data.LOG_UNSTACK_URL)

    @staticmethod
    def get_unstack_med():
        return Data._fetch_data(Data.MEDIAN_UNSTACK_URL)

    @staticmethod
    def get_unstack_raw():
        return Data._fetch_data(Data.RAW_UNSTACK_URL)

    @staticmethod
    def get_unstack_q85():
        return Data._fetch_data(Data.Q85_UNSTACK_URL)

    @staticmethod
    def get_unstack_q85_up40():
        return Data._fetch_data(Data.Q85_UP40_UNSTACK_URL)

    @staticmethod
    def get_log_stack():
        return Data._fetch_data(Data.LOG_STACK_URL)

    @staticmethod
    def get_standard_stack():
        return Data._fetch_data(Data.STANDARD_STACK_URL)

    @staticmethod
    def get_prepared_data():
        return Data._fetch_data(Data.DF_URL)
    
    @staticmethod
    def get_ks_dataset():
        df = Data._fetch_data(Data.KS_DATASET_URL)
        #Convert the number in the column name into integer
        df.columns = [int(col) if col.lstrip('-').isdigit() else col for col in df.columns]
        return df
        
    @staticmethod
    def get_ks():
        return Data._fetch_data(Data.KS_URL)
    
    @staticmethod
    def get_ks_upper():
        return Data._fetch_data(Data.KS_UPPER_URL)
    
    @staticmethod
    def get_ks_main_info():
        return Data._fetch_data(Data.KS_MAIN_INFO_URL)
    
    @staticmethod
    def get_ks_others():
        return Data._fetch_data(Data.KS_OTHERS_URL)
    
    @staticmethod
    def get_ks_others_info():
        return Data._fetch_data(Data.KS_OTHERS_INFO_URL)
    
    @staticmethod
    def get_pspa_upper():
        return Data._fetch_data(Data.PSPA_UPPER_URL)
    
    @staticmethod
    def get_pspa():
        return Data._fetch_data(Data.PSPA_URL)
    
    @staticmethod
    def get_pspa_original():
        return Data._fetch_data(Data.PSPA_ORIGINAL)
    
    @staticmethod
    def get_combine_upper():
        return Data._fetch_data(Data.COMBINE_UPPER_URL)
    
    @staticmethod
    def get_combine():
        return Data._fetch_data(Data.COMBINE_URL)
    
    
    # unique gene+site, but less cases
    @staticmethod
    def get_cptac_gene_site():
        return Data._fetch_data(Data.CPTAC_URL)
    
    # ensemblID + site, with more sites
    @staticmethod
    def get_cptac_ensembl_site():
        return Data._fetch_data(Data.CPTAC_KB_URL)
    
    @staticmethod
    def get_pplus_human_site():
        return Data._fetch_data(Data.PPLUS_HUMAN_URL)
    
    @staticmethod
    def get_ochoa_site():
        return Data._fetch_data(Data.OCHOA_URL)
    
    @staticmethod
    def get_cptac_unique_site():
        return Data._fetch_data(Data.CPTAC_UNIQUE_URL)
    

    

# %% ../nbs/00_core.ipynb 11
class CPTAC:
    """
    A class for fetching CPTAC phosphoproteomics data.
    """
    
    # Phosphoproteomics (Tumor)
    HNSCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/HNSCC/HNSCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    GBM = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/GBM/GBM_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    COAD = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    CCRCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/CCRCC/CCRCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    LSCC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LSCC/LSCC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    BRCA = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/BRCA/BRCA_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    UCEC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/UCEC/UCEC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    LUAD = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LUAD/LUAD_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    PDAC = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/PDAC/PDAC_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    OV = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/OV/OV_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
    
    # Phosphoproteomics (Normal)
    HNSCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/HNSCC/HNSCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    GBM_normal = None
    COAD_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    CCRCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/CCRCC/CCRCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    LSCC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LSCC/LSCC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    BRCA_normal = None
    UCEC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/UCEC/UCEC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    LUAD_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/LUAD/LUAD_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    PDAC_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/PDAC/PDAC_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    OV_normal = "https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/OV/OV_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"
    
    # Ensemble ID gene mapping
    HNSCC_ID = "https://zenodo.org/records/8196130/files/bcm-hnscc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    GBM_ID = "https://zenodo.org/records/8196130/files/bcm-gbm-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    COAD_ID = "https://zenodo.org/records/8196130/files/bcm-coad-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    CCRCC_ID = "https://zenodo.org/records/8196130/files/bcm-ccrcc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    LSCC_ID = "https://zenodo.org/records/8196130/files/bcm-lscc-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    BRCA_ID = "https://zenodo.org/records/8196130/files/bcm-brca-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    UCEC_ID = "https://zenodo.org/records/8196130/files/bcm-ucec-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    LUAD_ID = "https://zenodo.org/records/8196130/files/bcm-luad-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    PDAC_ID = "https://zenodo.org/records/8196130/files/bcm-pdac-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    OV_ID = "https://zenodo.org/records/8196130/files/bcm-ov-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
    
    
    def __init__(self):
        pass
    
    @staticmethod
    def _fetch_data(cancer, is_Tumor=True, is_KB=False):
        """
        Fetches the data from the given URL and returns a DataFrame
        """
        
        ID_URL = f"https://zenodo.org/records/8196130/files/bcm-{cancer.lower()}-mapping-gencode.v34.basic.annotation-mapping.txt.gz"
        if is_Tumor:
            DATA_URL = f"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/{cancer.upper()}/{cancer.upper()}_phospho_site_abundance_log2_reference_intensity_normalized_Tumor.txt"
        
        else:
            DATA_URL = f"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/{cancer.upper()}/{cancer.upper()}_phospho_site_abundance_log2_reference_intensity_normalized_Normal.txt"

            
        
        # Load ID data
        ref = pd.read_csv(ID_URL, compression='gzip', sep='\t')\
        [['protein','gene','gene_name']]\
        .drop_duplicates().reset_index(drop=True)
        
        
        # Load CPTAC phosphoproteomics data
        try:
            raw = pd.read_csv(DATA_URL, sep='\t')
        except Exception as e:
            print(f'{cancer}{e}')
        else:
            info = pd.DataFrame({'gene':raw.idx.str.split('|').str[0],
                         'site':raw.idx.str.split('|').str[2],
                         'site_seq':raw.idx.str.split('|').str[3]})
            # print(raw.columns[1:]) # patient ID

            print(f'the {cancer} dataset length is: {info.shape[0]}')

            # Merge ensembl ID with gene name
            info = info.merge(ref,'left')
            print(f'after id mapping, the length is {info.shape[0]}')

            print(f'{info.gene_name.isna().sum()} sites does not have a mapped gene name')

            info['gene_site'] = info['gene_name'] + '_' + info['site']
            info['protein_site'] = info['protein'].str.split('.').str[0] + '_' + info['site']

            if is_KB:
                info = info.drop_duplicates(subset='protein_site').reset_index(drop=True)
                print(f'after removing duplicates of protein_site, the length is {info.shape[0]}')
            else:
                info = info.drop_duplicates(subset='gene_site').reset_index(drop=True)
                print(f'after removing duplicates of gene_site, the length is {info.shape[0]}')



            return info
    
    
    @staticmethod
    def list_cancer():
        return ['HNSCC','GBM','COAD','CCRCC','LSCC','BRCA','UCEC','LUAD','PDAC','OV']

    @staticmethod
    def get_id(cancer_type,is_Tumor=True, is_KB=False):
        return CPTAC._fetch_data(cancer_type,is_Tumor, is_KB)


# %% ../nbs/00_core.ipynb 14
def extract_site_seq(df, # dataframe that contains protein sequence
                     seq_col, # column name of protein sequence
                     position_col # column name of position 0
                    ):
    """Extract -7 to +7 site sequence from protein sequence based on position 0 """
    
    data = []
    for i, r in tqdm(df.iterrows(),total=len(df)):
        position = r[position_col] - 1
        start = position - 7
        end = position + 8

        # Extract the subsequence
        subseq = r[seq_col][max(0, start):min(len(r[seq_col]), end)]

        # Pad the subsequence if needed
        if start < 0:
            subseq = "_" * abs(start) + subseq
        if end > len(r[seq_col]):
            subseq = subseq + "_" * (end - len(r[seq_col]))

        data.append(subseq)
    return np.array(data)

# %% ../nbs/00_core.ipynb 18
def raw2norm(df, #a single kinase's df that has position as index, and a.a. as columns
         PDHK=False, #whether this kinase belongs to PDHK family
        ):
    columns_to_exclude = ['S', 'T', 'C', 't', 'y']
    
    if PDHK:
        columns_to_exclude.append('Y')
        divisor = 16
    else:
        divisor = 17
    
    s = df.drop(columns=columns_to_exclude).sum(1)
    df2 = df.div(s, axis=0)
    df2.C = df2.C / (df2.C.median() * divisor)
    df2['S'] = df2.drop(columns=columns_to_exclude).median(1)
    df2['T'] = df2.drop(columns=columns_to_exclude).median(1)
    df2 = round(df2, 4)
    
    return df2

# %% ../nbs/00_core.ipynb 19
def get_one_kinase(df, #stacked dataframe (paper's raw data)
               kinase, # a specific kinase
               normalize=False, # normalize according to the paper; special for PDHK1/4
                drop_s = True # drop s if s is in column
              ):
    "Obtain a specific kinase data from stacked dataframe, decide whether or not to normalize"
    
    p = pd.DataFrame(df.loc[kinase],columns = [kinase]).reset_index().rename(columns={'index':'substrate'})
    p['position'] = p.substrate.str.extract('(-?\d+)')
    p['aa'] = p.substrate.str[-1]
    p.position = p.position.astype(int)
    pp = p.pivot(index='position', columns='aa', values=kinase)
    if drop_s:
        if 's' in pp.columns:
            pp = pp.drop(columns=['s'])

    if normalize:
        pp = raw2norm(pp, PDHK=True if kinase == 'PDHK1' or kinase == 'PDHK4' else False)
    return pp

# %% ../nbs/00_core.ipynb 32
def unstack(df, name):
    # Unstack
    df = df.unstack().reset_index(name = name)
    
    # Rename column
    df = df.rename(columns = {'level_0':'substrate'})
    
    # Reorder column
    df = df[['kinase','substrate',name]]
    
    # Deal with some warning issue
    df = df.copy()
    
    # Divide substrate info into position and aa
    df['position'] = df.substrate.str.extract('(-?\d+)')
    df['aa'] = df.substrate.str[-1]
    
    # Remove 's' as it is a duplicate of 't'
    df = df[df['aa'] != 's'].reset_index(drop=True)
    
    return df

# %% ../nbs/00_core.ipynb 35
def get_dict(input_string):
    "Get dictionary of input string; no need for the star in the middle; make sure it is 15 or 10 length"

    center_index = len(input_string) // 2
    center_char = input_string[center_index]

    result = []

    for i, char in enumerate(input_string):
        position = i - center_index

        if char.isalpha():
            result.append(f"{position}{char}")

    return result

# %% ../nbs/00_core.ipynb 43
def multiply(values, kinase):
    divide = 16 if 'PDHK' in kinase else 17

    # Using the logarithmic property: log(a*b) = log(a) + log(b)
    # Compute the sum of the logarithms of the values and the divide factor
    log_sum = np.sum(np.log2(values)) + (len(values) - 1) * np.log2(divide)

    return log_sum

# %% ../nbs/00_core.ipynb 48
def sumup(values,kinase=None):
    return sum(values)

# %% ../nbs/00_core.ipynb 49
def predict_kinase(input_string, # site sequence
                          ref, # reference dataframe for scoring
                          func = sumup # function to calculate score
                         ):
    results=[]
    for kinase,row in tqdm(ref.iterrows(), total=ref.shape[0]):
        r_dict = row.to_dict() # To hash
        # result = []
        
        pos_aa_name=get_dict(input_string)
        pos_aa_name = [key for key in pos_aa_name if key in ref.columns]
        
        pos_aa_val = [r_dict[key] for key in pos_aa_name]

        score = func(pos_aa_val,kinase)
        results.append(score)
    
    print(f'calculated string: {pos_aa_name}')

    out = pd.Series(results,index=ref.index).sort_values(ascending=False)
        
    return out.round(3)

# %% ../nbs/00_core.ipynb 50
def predict_kinase_df(df, # dataframe that contains site sequence
                   ref, # reference df for scoring
                   seq_col, # column name of site sequence
                   seq_id=None, # column name of site id
                   func = sumup # function to calculate score
                     ):
    results=[]
    num = list(set(ref.columns.str[:-1].astype(int)))
    num.sort()
    print(f'according to the ref \nwill calculate position: {num}')
    
    for kinase,row in tqdm(ref.iterrows(), total=ref.shape[0]):
        r_dict = row.to_dict() # To hash
        result = []
        for input_string in df[seq_col]:
            pos_aa_name=get_dict(input_string)
            pos_aa_val = [r_dict[key] for key in pos_aa_name]
            
            score = func(pos_aa_val,kinase)
            result.append(score)

        results.append(result)
        
        
    if seq_id is not None:
        out =pd.DataFrame(results,index=ref.index,columns=df[seq_id]).T
    else:
        out =pd.DataFrame(results,index=ref.index).T
        
    return out

# %% ../nbs/00_core.ipynb 71
def agg_seq(df, # contains split columns
            agg_col = None, # column of weight, if None, will count number
           ):
    melt = df.melt(id_vars=agg_col,value_vars=[i for i in range(-7,8)])
    if agg_col is not None:
        # aggregate by the values
        agg = melt.groupby(['variable','value']).agg({agg_col:sum}).reset_index()
    else:
        # aggregate by the count
        agg = melt.groupby(['variable','value']).size().reset_index()
    pivot = agg.pivot(index='value',columns='variable',values=agg.columns[-1])
    # aa_order = [i for i in 'PGACSTVILMFYWHKRQNDEsty']
    aa_order = [i for i in 'PGACSTVILMFYWHKRQNDE']
    pivot = pivot.reindex(index=aa_order).fillna(0)
    return pivot

# %% ../nbs/00_core.ipynb 73
def get_freq(df_k,
             aa_order = [i for i in 'PGACSTVILMFYWHKRQNDEsty'],
            aa_order_paper = [i for i in 'PGACSTVILMFYWHKRQNDEsty'],
             position = [i for i in range(-7,8)],
             position_paper = [-5,-4,-3,-2,-1,1,2,3,4]
            ):
    
    "Get frequency of each amino acid at each position"
    

    #Count frequency for each amino acid at each position
    melted_k = df_k.melt(id_vars=['Kinase', 'substrate'], 
                    value_vars=[i for i in range(-7, 8)],
                    var_name='Position', 
                    value_name='aa')
    
    # Group by Position and Amino Acid and count occurrences
    grouped = melted_k.groupby(['Position', 'aa']).size().reset_index(name='Count')
    

    # Remove wired amino acid
    aa_include = [i for i in 'PGACSTVILMFYWHKRQNDEsty']
    grouped = grouped[grouped.aa.isin(aa_include)].reset_index(drop=True)
    
    # get pivot table
    pivot_k = grouped.pivot(index='aa', columns='Position', values='Count').fillna(0)
    
    # Get frequency by dividing the sum of each column
    freq_k = pivot_k/pivot_k.sum()

    
    # data from the kinase-substrate dataset, and format is Lew's paper's format
    paper = freq_k.reindex(index=aa_order_paper,columns=position_paper,fill_value=0)

    # full pivot data from kinase-substrate dataset
    full = freq_k.reindex(index=aa_order,columns=position, fill_value=0)

    
    return paper,full
