# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_DLmodel.ipynb.

# %% auto 0
__all__ = ['GeneralDataset', 'MLP1', 'dl_trainer', 'dl_predict']

# %% ../nbs/04_DLmodel.ipynb 4
from fastbook import *
import xgboost as xgb
from scipy.stats import spearmanr,pearsonr
from .core import Data
from .feature import *
from sklearn.model_selection import train_test_split, StratifiedGroupKFold

# %% ../nbs/04_DLmodel.ipynb 6
class GeneralDataset:
    def __init__(self, df, feature_cols, target_cols=None):
        
        self.test = False if target_cols is not None else True
        
        self.X = df[feature_cols].values 
        self.y = df[target_cols].values if not self.test else None
        
        self.len = df.shape[0]

    def __len__(self):
        return self.len

    def __getitem__(self, index):
        X = torch.Tensor(self.X[index])
        if self.test:
            return X
        else:
            y = torch.Tensor(self.y[index])
            return X, y

# %% ../nbs/04_DLmodel.ipynb 8
def MLP1(in_channel, out_channel,dp = 0.2):
    model = nn.Sequential(
        nn.Linear(in_channel, 512),
        nn.BatchNorm1d(512),
        nn.Dropout(dp),
        nn.PReLU(),
        nn.Linear(512, 218),
        nn.BatchNorm1d(218),
        nn.Dropout(dp),
        nn.PReLU(),
        nn.Linear(218, out_channel)
    )
    return model

# %% ../nbs/04_DLmodel.ipynb 10
def dl_trainer(df, # dataframe contains features and targets
               splits, # tuple (train_index, valid_index)
               feat_col, # ['feat1', 'feat2', ...]
               target_col, # ['target1']
               model, # pytorch model
               loss, # loss function
               save, # string, it will save to models/name.pth
               epochs=4, # epochs to train
              ):
    
    train = df.loc[splits[0]]
    valid = df.loc[splits[1]]
    
    train_ds = GeneralDataset(train, feat_col, target_col)
    valid_ds = GeneralDataset(valid, feat_col, target_col)

    dls = DataLoaders.from_dsets(train_ds, valid_ds, num_workers=4)
    
    learn = Learner(dls.cuda(), model.cuda(), loss)
    
    lr_max = learn.lr_find()
    plt.show()
    plt.close()
    print(lr_max)
    
    # cbs = [
    #    SaveModelCallback(with_opt=True), # optimizer=True, can also set monitor
    #    EarlyStoppingCallback(patience=3), # monitor
    #   ]
    
    learn.fit_one_cycle(epochs, lr_max) # cbs= cbs
    
    if save is not None:
        learn.save(save)
    
    return learn

# %% ../nbs/04_DLmodel.ipynb 11
def dl_predict(df, feat_col, model, checkpoint_pth):
    test_dset = GeneralDataset(df,feat_col)
    test_dl = torch.utils.data.DataLoader(test_dset)
    
    learn = Learner(None, model.cuda(), loss_func=1)
    learn.load(checkpoint_pth)
    
    learn.model.eval()
    
    preds = []
    for data in test_dl:
        inputs = data.cuda()
        outputs = learn.model(inputs) #learn.model(x).sigmoid().detach().cpu().numpy()

        preds.append(outputs.detach().cpu().numpy())

    preds = np.concatenate(preds)
    
    pred_df = df.copy()
    pred_df['pred'] = preds
    
    return pred_df
