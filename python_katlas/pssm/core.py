"""Functions related with PSSMs"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/02a_pssm_core.ipynb.

# %% auto #0
__all__ = ['EPSILON', 'get_prob', 'get_pssm_weight', 'flatten_pssm', 'recover_pssm', 'clean_zero_normalize', 'get_cluster_pssms',
           'get_entropy', 'get_entropy_flat', 'get_IC', 'get_IC_flat', 'get_specificity', 'get_specificity_flat']

# %% ../../nbs/02a_pssm_core.ipynb #05668c38
import numpy as np, pandas as pd
from katlas.data import *
from katlas.utils import *
from fastcore.meta import delegates
from tqdm import tqdm
from tqdm.contrib.concurrent import process_map
from functools import partial

# for type
from typing import Sequence

# %% ../../nbs/02a_pssm_core.ipynb #4f3b7938
EPSILON = 1e-8

# %% ../../nbs/02a_pssm_core.ipynb #be1756c3
def get_prob(data: pd.DataFrame | pd.Series | Sequence[str], # input data, list or df
             col: str='site_seq', # column name if input is df
             ):
    "Get the probability matrix of PSSM from phosphorylation site sequences."

    aa_order=[i for i in 'PGACSTVILMFYWHKRQNDEsty']

    if isinstance(data, pd.DataFrame):
        if col not in data.columns:
            raise ValueError(f"Column '{col}' not found in DataFrame.")
        site = data[col]
    else:
        if isinstance(data, (str, bytes)):
            raise TypeError("Input looks like a single sequence string; pass [seq] or a Series instead.")
        try:
            site = pd.Series(data,copy=False)
        except Exception:
            raise TypeError("Input must be a DataFrame, Series, or list of sequences.")
    
    
    site = check_seqs(site)
    
    site_array = np.array(site.apply(list).tolist())
    seq_len = site_array.shape[1]
    # if seq_len % 2 == 0: raise ValueError(f"Expected odd sequence length (centered window). Got even length: {seq_len}")

    position = list(range(-(seq_len // 2), (seq_len // 2)+1)) # add 1 because range do not include the final num
    
    site_df = pd.DataFrame(site_array, columns=position)
    melted = site_df.melt(var_name='Position', value_name='aa')
    
    grouped = melted.groupby(['Position', 'aa']).size().reset_index(name='Count')
    grouped = grouped[grouped.aa.isin(aa_order)].reset_index(drop=True)
    
    pivot_df = grouped.pivot(index='aa', columns='Position', values='Count').fillna(0)
    pssm_df = pivot_df / pivot_df.sum()

    ordered_aa = [aa for aa in aa_order if aa in pssm_df.index]
    pssm_df = pssm_df.reindex(index=ordered_aa, columns=position, fill_value=0)
    
    return pssm_df

# %% ../../nbs/02a_pssm_core.ipynb #b299a7c7
def get_pssm_weight(
    data: pd.DataFrame,
    seq_col: str = "seq",
    score_col: str = "enrichment",          # selected/input ratio OR already-log2
    to_log2: bool = True,
    aa_order: str = "PGACSTVILMFYWHKRQNDEsty",
    center: str='pos',# per-position median centering or 'glob' global median centering
    count_thr: int=5, # threshold to filter out if <count_thr
    alpha: str|float = 'auto', # shrinkage strength: value * count / (count + alpha)
):
    """
    Position-specific amino acid enrichment matrix:
    PSSM(aa,pos) = mean( log2(score) ) over peptides with aa at pos.
    """
    # --- get sequences + scores ---
    if isinstance(data, pd.DataFrame):
        if seq_col not in data.columns:
            raise ValueError(f"Column '{seq_col}' not found.")
        if score_col not in data.columns:
            raise ValueError(f"Column '{score_col}' not found.")
        seq = data[seq_col].astype(str)
        score = pd.to_numeric(data[score_col], errors="coerce")
        d = pd.DataFrame({"seq": seq, "score": score})
    else:
        # if only pass sequences, this cannot compute enrichment-based PSSM
        raise TypeError("For enrichment-based PSSM, pass a DataFrame with seq_col and score_col.")

    # basic QC
    d = d.dropna(subset=["seq", "score"]).copy()
    d = d[d["seq"].str.len() == d["seq"].str.len().mode()[0]]  # keep modal length (usually 11)

    seq_len = int(d["seq"].str.len().iloc[0])
    center_idx = seq_len // 2

    # log2 transform
    if to_log2:
        # score is selected/input ratio; must be >0
        d = d[d["score"] > 0].copy()
        d["L"] = np.log2(d["score"].astype(float))
    else:
        d["L"] = d["score"].astype(float)

    # positions labels (-5..+5 for length 11)
    positions = list(range(-center_idx, center_idx + 1))

    # explode sequence into columns
    site_array = np.array(d["seq"].apply(list).tolist())
    site_df = pd.DataFrame(site_array, columns=positions)
    site_df["L"] = d["L"].to_numpy()

    # melt so each residue-position pair carries the peptide's log2 enrichment
    melted = site_df.melt(id_vars="L", var_name="Position", value_name="aa")

    # keep only those in AA order
    aa_order_list = [a for a in aa_order if a in melted["aa"].unique()]
    melted = melted[melted["aa"].isin(aa_order_list)]

    # aggregate: mean log2 enrichment for (Position, aa)
    stats = (
        melted.groupby(["aa", "Position"])["L"]
        .agg(["mean", "count"])
        .reset_index()
    )
    
    # build matrices
    pssm = stats.pivot(index="aa", columns="Position", values="mean")
    counts = stats.pivot(index="aa", columns="Position", values="count")

    # shrinkage
    if alpha is not None:
        if alpha=='auto':
            c = counts.to_numpy().ravel()
            c = c[c > 0]
            a = 0.5* np.median(c)
        elif isinstance(alpha,(int,float)):
            a = float(alpha)
        else:
            raise ValueError("alpha must be None, 'auto', or a numeric value")
        shrink_factor = counts / (counts + a)
        pssm = pssm * shrink_factor

    # mask low-support cells
    pssm[counts < count_thr] = np.nan

    # optional centering
    if center=='pos': pssm = pssm - pssm.median()
    elif center=='glob': pssm = pssm - np.nanmedian(pssm.to_numpy())

    return pssm.reindex(aa_order_list)

# %% ../../nbs/02a_pssm_core.ipynb #e7f01a7f
def flatten_pssm(pssm_df,
                 column_wise=True, # if True, column major flatten; else row wise flatten (for pytorch training)
                ):
    "Flatten PSSM dataframe to dictionary"
    
    pssm_df=pssm_df.copy()

    # Flatten a pssm_df
    # Column wise
    if column_wise: 
        pssm = pssm_df.unstack().reset_index(name='value')
        # Combine position column and residue identity column as new column for keys
        pssm['position_residue']=pssm.iloc[:,0].astype(str)+pssm.iloc[:,1]
        
    # Row wise
    else: 
        pssm = pssm_df.T.unstack().reset_index(name='value')
        pssm['position_residue']=pssm.iloc[:,1].astype(str)+pssm.iloc[:,0].astype(str)
    
    # Set index to be position+residue
    return pssm.set_index('position_residue')['value'].to_dict()

# %% ../../nbs/02a_pssm_core.ipynb #b4d2f50e
def recover_pssm(flat_pssm: pd.Series):
    "Recover 2D PSSM from flattened PSSM Series."
    df = flat_pssm.reset_index()
    df.columns=['index', 'value']
    df['Position'] = df['index'].str[:-1].astype(int)
    df['aa'] = df['index'].str[-1]

    df = df.pivot(index='aa', columns='Position', values='value').fillna(0)
    aa_order=tuple('PGACSTVILMFYWHKRQNDEsty')
    order = [aa for aa in aa_order if aa in df.index]
    return df.reindex(index=order).sort_index(axis=1)

# %% ../../nbs/02a_pssm_core.ipynb #500f8e48
def _clean_zero(pssm_df):
    "Zero out non-last three values in position 0 (keep only s,t,y values at center)"
    pssm_df = pssm_df.copy()
    standard_aa = list(set(pssm_df.index)-set(['s','t','y']))
    pssm_df.loc[standard_aa, 0] = 0
    return pssm_df

# %% ../../nbs/02a_pssm_core.ipynb #38c65527
def clean_zero_normalize(pssm_df):
    "Zero out non-last three values in position 0 (keep only s,t,y values at center), and normalize per position"
    pssm_df=pssm_df.copy()
    pssm_df.columns= pssm_df.columns.astype(int)
    pssm_df = _clean_zero(pssm_df)
    return pssm_df/pssm_df.sum()

# %% ../../nbs/02a_pssm_core.ipynb #86bffb81
def get_cluster_pssms(df, 
                    cluster_col, 
                    seq_col='site_seq', 
                    id_col = 'sub_site',
                    count_thr=10, # if less than the count threshold, not include in the return
                    valid_thr=None, # percentage of not-nan values in pssm
                      plot=False):
    "Extract motifs from clusters in a dataframe"
    pssms = []
    ids = []
    # drop duplicates based both on cluster column and substrate seq id column
    if id_col is not None: df = df.drop_duplicates(subset=[cluster_col,id_col]).copy()
    value_counts = df[cluster_col].value_counts()
    
    for cluster_id, counts in tqdm(value_counts.items(),total=len(value_counts)):
        if count_thr is not None and counts < count_thr:
            continue
            
        df_cluster = df[df[cluster_col] == cluster_id]
        n= len(df_cluster)
        pssm = get_prob(df_cluster, seq_col)
        valid_score = (pssm != 0).sum().sum() / (pssm.shape[0] * pssm.shape[1])

        if valid_thr is not None and valid_score <= valid_thr:
            continue

        pssms.append(flatten_pssm(pssm))
        ids.append(cluster_id)

        if plot:
            plot_logo(pssm, title=f'Cluster {cluster_id} (n={n})', figsize=(14, 1))
            plt.show()
            plt.close()

    pssm_df = pd.DataFrame(pssms, index=ids)
    return pssm_df

# %% ../../nbs/02a_pssm_core.ipynb #fcc45adc
def get_entropy(pssm_df,# a dataframe of pssm with index as aa and column as position
            return_min=False, # return min entropy as a single value or return all entropy as a pd.series
            exclude_zero=False, # exclude the column of 0 (center position) in the entropy calculation
            clean_zero=True, # if true, zero out non-last three values in position 0 (keep only s,t,y values at center)
            ): 
    "Calculate entropy per position of a PSSM surrounding 0. The less entropy the more information it contains."
    pssm_df = pssm_df.copy()
    pssm_df.columns= pssm_df.columns.astype(int)
    if 0 in pssm_df.columns:
        if clean_zero:                       
            pssm_df = _clean_zero(pssm_df)
        if exclude_zero:
            # remove columns starts with zero and columns with interger name 0
            cols_to_drop = [col for col in pssm_df.columns 
                            if col == 0 or (isinstance(col, str) and col.startswith('0'))]
            if cols_to_drop: pssm_df = pssm_df.drop(columns=cols_to_drop)

    pssm_df = pssm_df/pssm_df.sum()
    per_position = -np.sum(pssm_df * np.log2(pssm_df + EPSILON), axis=0)
    per_position[pssm_df.sum() == 0] = 0
    return float(per_position.min()) if return_min else per_position

# %% ../../nbs/02a_pssm_core.ipynb #42819467
@delegates(get_entropy)
def get_entropy_flat(flat_pssm:pd.Series,**kwargs): 
    "Calculate entropy per position of a flat PSSM surrounding 0"
    pssm_df = recover_pssm(flat_pssm)
    return get_entropy(pssm_df,**kwargs)

# %% ../../nbs/02a_pssm_core.ipynb #b43220de
@delegates(get_entropy)
def get_IC(pssm_df,**kwargs):
    """
    Calculate the information content (bits) from a frequency matrix,
    using log2(3) for the middle position and log2(len(pssm_df)) for others.
    The higher the more information it contains.
    """
    
    entropy_position = get_entropy(pssm_df,**kwargs)
    
    max_entropy_array = pd.Series(np.log2(len(pssm_df)), index=entropy_position.index)

    # set exclude_zero to False
    exclude_zero = kwargs.get('exclude_zero', False)
    if exclude_zero is False: max_entropy_array[0] = np.log2(3)

    # information_content = max_entropy - entropy --> log2(N) - entropy
    IC_position = max_entropy_array - entropy_position

    # if entropy is zero, set to zero as there's no value
    IC_position[entropy_position == 0] = 0
    return IC_position

# %% ../../nbs/02a_pssm_core.ipynb #3db4bb1a
@delegates(get_IC)
def get_IC_flat(flat_pssm:pd.Series,**kwargs):
    """Calculate the information content (bits) from a flattened pssm pd.Series,
    using log2(3) for the middle position and log2(len(pssm_df)) for others."""
    
    pssm_df = recover_pssm(flat_pssm)
    return get_IC(pssm_df,**kwargs)

# %% ../../nbs/02a_pssm_core.ipynb #87cde6c1
def get_specificity(pssm_df):
    "Get specificity score of a pssm, excluding zero position."
    ICs = get_IC(pssm_df, exclude_zero=True)
    # only consider IC with values
    ICs= ICs[ICs > 0]
    return float(2*ICs.max()+ICs.var())

# %% ../../nbs/02a_pssm_core.ipynb #887e0002
def get_specificity_flat(flat_pssm):
    "Get specificity score of a pssm, excluding zero position."
    ICs = get_IC_flat(flat_pssm, exclude_zero=True)
    return float(2*ICs.max()+ICs.var())
