{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c420117e-3861-4c3c-98d0-747ea66e12a7",
   "metadata": {},
   "source": [
    "# Analyze\n",
    "\n",
    "> Functions for downstream analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb551a-d9c2-4aa9-8754-80e3122a3779",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb40e2-697e-44f9-a12d-628a5d181406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14916737-bbe4-4acd-805b-82a4aa0d9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "\n",
    "# P value session\n",
    "import math\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, wilcoxon,chi2\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff911ad-4361-4d4f-b9c6-ae6a5abda01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c17788-ccc6-4b8a-84be-6db90ed33da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pd.set_option('display.max_rows', 5)\n",
    "pd.set_option('display.max_columns', 100) # show all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296d4c4-83dd-4944-a641-d42e70e0accf",
   "metadata": {},
   "source": [
    "```python\n",
    "from katlas.analyze import *\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07852796-c74b-4f91-bcff-88e4d457e266",
   "metadata": {},
   "source": [
    "## P values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675297a-a363-41f5-99b7-844de32c26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_pvalue(df,\n",
    "              columns1, # list of column names for group1\n",
    "              columns2, # list of column names for group2\n",
    "              test_method = 'mann_whitney', # 'student_t', 'mann_whitney', 'wilcoxon'\n",
    "              FC_method = 'median', # or mean\n",
    "             ):\n",
    "\n",
    "    \"Performs statistical tests and calculates difference between the median or mean of two groups of columns.\"\n",
    "\n",
    "    group1 = df[columns1]\n",
    "    group2 = df[columns2]\n",
    "\n",
    "    # Compute median values for each gene in both groups\n",
    "    if FC_method == \"median\":\n",
    "        m1 = group1.median(axis=1)\n",
    "        m2 = group2.median(axis=1)\n",
    "    elif FC_method == \"mean\":\n",
    "        m1 = group1.mean(axis=1)\n",
    "        m2 = group2.mean(axis=1)\n",
    "\n",
    "    # As phosphoproteomics data has already been log transformed, we can directly use subtraction\n",
    "    FCs = m2 - m1\n",
    "\n",
    "    # Perform the chosen test and handle NaN p-values\n",
    "    if test_method == 'student_t': # data is normally distributed, non-paired\n",
    "        test_func = ttest_ind\n",
    "    elif test_method == 'mann_whitney': # not normally distributed, non-paired, mann_whitney considers the rank, ignore the differences\n",
    "        test_func = mannwhitneyu\n",
    "    elif test_method == 'wilcoxon': # not normally distributed, paired\n",
    "        test_func = wilcoxon\n",
    "\n",
    "    t_results = []\n",
    "    for idx in tqdm(df.index, desc=f\"Computing {test_method} tests\"):\n",
    "        try:\n",
    "            if test_method == 'wilcoxon': # as wilcoxon is paired, if lack a paired sample, just give nan, as default nanpolicy is propagate (gives nan if nan in input)\n",
    "                stat, pvalue = test_func(group1.loc[idx], group2.loc[idx])\n",
    "            else:\n",
    "                stat, pvalue = test_func(group1.loc[idx], group2.loc[idx], nan_policy='omit')\n",
    "        except ValueError:  # Handle cases with insufficient data\n",
    "            pvalue = np.nan\n",
    "        t_results.append(pvalue)\n",
    "\n",
    "    # Exclude NaN p-values before multiple testing correction\n",
    "    p_values = np.array(t_results, dtype=float)  # Ensure the correct data type\n",
    "    valid_p_values = p_values[~np.isnan(p_values)]\n",
    "\n",
    "    # Adjust for multiple testing on valid p-values only\n",
    "    reject, pvals_corrected, _, _ = multipletests(valid_p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    # Create a full list of corrected p-values including NaNs\n",
    "    full_pvals_corrected = np.full_like(p_values, np.nan)\n",
    "    np.place(full_pvals_corrected, ~np.isnan(p_values), pvals_corrected)\n",
    "\n",
    "    # Adjust the significance accordingly\n",
    "    full_reject = np.zeros_like(p_values, dtype=bool)\n",
    "    np.place(full_reject, ~np.isnan(p_values), reject)\n",
    "\n",
    "    # Create DataFrame with results\n",
    "    results = pd.DataFrame({\n",
    "        'log2FC': FCs,\n",
    "        'p_value': p_values,\n",
    "        'p_adj': full_pvals_corrected\n",
    "    })\n",
    "\n",
    "    results['p_value'] = results['p_value'].astype(float)\n",
    "\n",
    "    def get_signed_logP(r,p_col):\n",
    "        log10 = -np.log10(r[p_col])\n",
    "        return -log10 if r['log2FC']<0 else log10\n",
    "\n",
    "    results['signed_logP'] = results.apply(partial(get_signed_logP,p_col='p_value'),axis=1)\n",
    "    results['signed_logPadj'] = results.apply(partial(get_signed_logP,p_col='p_adj'),axis=1)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f7ec9-f30e-414c-aa2a-68584acbe934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_metaP(p_values):\n",
    "    \n",
    "    \"Use Fisher's method to calculate a combined p value given a list of p values; this function also allows negative p values (negative correlation)\"\n",
    "\n",
    "    logs = [math.log(abs(p))*-1 if p<0 else math.log(abs(p)) for p in p_values]\n",
    "    chi_square_stat = -2 * sum(logs)\n",
    "    degrees_of_freedom = 2 * len(p_values)\n",
    "    score = chi2.sf(abs(chi_square_stat), degrees_of_freedom)*-1 if chi_square_stat<0 else chi2.sf(abs(chi_square_stat), degrees_of_freedom)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f45ee-ff4e-4c3d-a659-64344fad42cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003626876953231754"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = [0.001,-0.5,0.002]\n",
    "\n",
    "get_metaP(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8132f2-3762-4152-9621-ca946bac7ea6",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816d52c-4200-420d-b8dd-0f241d747c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f4ec95-f2d1-4341-b5a9-ab17583ced6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
