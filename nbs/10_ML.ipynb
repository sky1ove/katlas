{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML\n",
    "\n",
    "> A collection of machine learning tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# katlas\n",
    "from katlas.data import Data\n",
    "from katlas.pssm import *\n",
    "from katlas.feature import *\n",
    "from katlas.clustering import *\n",
    "from functools import partial\n",
    "\n",
    "# essentials\n",
    "import pandas as pd, numpy as np\n",
    "from joblib import dump, load\n",
    "import math,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# scipy\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_splits(df: pd.DataFrame, # df contains info for split\n",
    "               stratified: str=None, # colname to make stratified kfold; sampling from different groups\n",
    "               group: str=None, # colname to make group kfold; test and train are from different groups\n",
    "               nfold: int=5,\n",
    "               seed: int=123):\n",
    "    \n",
    "    \"Split samples in a dataframe based on Stratified, Group, or StratifiedGroup Kfold method\"\n",
    "    def _log(colname):\n",
    "        print(kf)\n",
    "        split=splits[0]\n",
    "        print(f'# {colname} in train set: {df.loc[split[0]][colname].unique().shape[0]}')\n",
    "        print(f'# {colname} in test set: {df.loc[split[1]][colname].unique().shape[0]}')\n",
    "        \n",
    "    splits = []\n",
    "    if stratified is not None and group is None:\n",
    "        kf = StratifiedKFold(nfold, shuffle=True, random_state=seed)\n",
    "        for split in kf.split(df.index, df[stratified]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(stratified)\n",
    "        \n",
    "    elif group is not None and stratified is None:\n",
    "        kf = GroupKFold(nfold)\n",
    "        for split in kf.split(df.index, groups=df[group]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(group)\n",
    "        \n",
    "    elif stratified is not None and group is not None:\n",
    "        kf = StratifiedGroupKFold(nfold, shuffle=True, random_state=seed)\n",
    "        for split in kf.split(df.index, groups=df[group], y=df[stratified]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(stratified)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either 'stratified' or 'group' argument must be provided.\")\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_data.ipynb\t       06_pathway.ipynb     _11_DNN.ipynb     nbdev.yml\n",
      "01_utils.ipynb\t       07_alignment.ipynb   _nbs_names.ipynb  paper\n",
      "02_pssm.ipynb\t       08_statistics.ipynb  _old.ipynb\t      styles.css\n",
      "03_hierarchical.ipynb  10_ML.ipynb\t    _quarto.yml       tutorials\n",
      "03_scoring.ipynb       11_DNN.ipynb\t    custom.scss\n",
      "04_feature.ipynb       Untitled.ipynb\t    index.ipynb\n",
      "05_plot.ipynb\t       _11_DL.ipynb\t    models\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet('paper/kinase_domain/train/pspa_t5.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold(n_splits=5, random_state=None, shuffle=False)\n",
      "# subfamily in train set: 120\n",
      "# subfamily in test set: 29\n"
     ]
    }
   ],
   "source": [
    "info=Data.get_kinase_info()\n",
    "\n",
    "info = info[info.pseudo=='0']\n",
    "\n",
    "info = info[info.kd_ID.notna()]\n",
    "\n",
    "subfamily_map = info[['kd_ID','subfamily']].drop_duplicates().set_index('kd_ID')['subfamily']\n",
    "\n",
    "pspa_info = pd.DataFrame(df.index.tolist(),columns=['kinase'])\n",
    "\n",
    "pspa_info['subfamily'] = pspa_info.kinase.map(subfamily_map)\n",
    "\n",
    "splits = get_splits(pspa_info, group='subfamily',nfold=5)\n",
    "\n",
    "split0 = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', '-5P', '-4P', '-3P', '-2P', '-1P', '0P', '1P', '2P', '3P',\n",
       "       ...\n",
       "       'T5_1014', 'T5_1015', 'T5_1016', 'T5_1017', 'T5_1018', 'T5_1019',\n",
       "       'T5_1020', 'T5_1021', 'T5_1022', 'T5_1023'],\n",
       "      dtype='object', length=1255)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column name of feature and target\n",
    "feat_col = df.columns[df.columns.str.startswith('T5_')]\n",
    "target_col = df.columns[~df.columns.isin(feat_col)][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T5_0', 'T5_1', 'T5_2', 'T5_3', 'T5_4', 'T5_5', 'T5_6', 'T5_7', 'T5_8',\n",
       "       'T5_9',\n",
       "       ...\n",
       "       'T5_1014', 'T5_1015', 'T5_1016', 'T5_1017', 'T5_1018', 'T5_1019',\n",
       "       'T5_1020', 'T5_1021', 'T5_1022', 'T5_1023'],\n",
       "      dtype='object', length=1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['-5P', '-4P', '-3P', '-2P', '-1P', '0P', '1P', '2P', '3P', '4P',\n",
       "       ...\n",
       "       '-5pY', '-4pY', '-3pY', '-2pY', '-1pY', '0pY', '1pY', '2pY', '3pY',\n",
       "       '4pY'],\n",
       "      dtype='object', length=230)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_data(df: pd.DataFrame, # dataframe of values\n",
    "               feat_col: list, # feature columns\n",
    "               target_col: list, # target columns\n",
    "               split: tuple # one of the split in splits\n",
    "               ):\n",
    "    \"Given split tuple, split dataframe into X_train, y_train, X_test, y_test\"\n",
    "    \n",
    "    X_train = df.loc[split[0]][feat_col]\n",
    "    y_train = df.loc[split[0]][target_col]\n",
    "    \n",
    "    X_test = df.loc[split[1]][feat_col]\n",
    "    y_test = df.loc[split[1]][target_col]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(df,feat_col, target_col, split0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((294, 1024), (294, 230), (74, 1024), (74, 230))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_ml(df, # dataframe of values\n",
    "             feat_col, # feature columns\n",
    "             target_col, # target columns\n",
    "             split, # one split in splits\n",
    "             model,  # a sklearn models\n",
    "             save = None, # file (.joblib) to save, e.g. 'model.joblib'\n",
    "             params={}, # parameters for model.fit from sklearn\n",
    "            ):\n",
    "    \n",
    "    \"Fit and predict using sklearn model format, return target and pred of valid dataset.\"\n",
    "    \n",
    "    # split data\n",
    "    X_train, y_train, X_test, y_test = split_data(df, feat_col, target_col, split)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, **params) # better convert y_train to numpy array and flatten\n",
    "    \n",
    "    if save is not None:\n",
    "        # Save the model to a file\n",
    "        # joblib.dump(model, save)\n",
    "        dump(model, save)\n",
    "        \n",
    "    # Predict train\n",
    "    y_train_pred = model.predict(X_train) # X_test is dataframe, y_pred is numpy array\n",
    "    \n",
    "    # Predict test\n",
    "    y_pred = model.predict(X_test) # X_test is dataframe, y_pred is numpy array\n",
    "\n",
    "    # Make dataframe\n",
    "    y_pred = pd.DataFrame(y_pred,index=y_test.index, columns = y_test.columns)\n",
    "    \n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-5P</th>\n",
       "      <th>-4P</th>\n",
       "      <th>-3P</th>\n",
       "      <th>-2P</th>\n",
       "      <th>-1P</th>\n",
       "      <th>0P</th>\n",
       "      <th>1P</th>\n",
       "      <th>2P</th>\n",
       "      <th>3P</th>\n",
       "      <th>4P</th>\n",
       "      <th>...</th>\n",
       "      <th>-5pY</th>\n",
       "      <th>-4pY</th>\n",
       "      <th>-3pY</th>\n",
       "      <th>-2pY</th>\n",
       "      <th>-1pY</th>\n",
       "      <th>0pY</th>\n",
       "      <th>1pY</th>\n",
       "      <th>2pY</th>\n",
       "      <th>3pY</th>\n",
       "      <th>4pY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.025734</td>\n",
       "      <td>0.037940</td>\n",
       "      <td>0.066932</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.073621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076180</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>-0.005546</td>\n",
       "      <td>0.042921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075505</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.055032</td>\n",
       "      <td>0.080379</td>\n",
       "      <td>-0.017676</td>\n",
       "      <td>-0.038610</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.084595</td>\n",
       "      <td>0.052408</td>\n",
       "      <td>0.032714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.029486</td>\n",
       "      <td>0.041007</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>-0.007920</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025618</td>\n",
       "      <td>0.023630</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.035469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095213</td>\n",
       "      <td>0.067924</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.083987</td>\n",
       "      <td>0.059089</td>\n",
       "      <td>-0.037290</td>\n",
       "      <td>0.042184</td>\n",
       "      <td>0.076801</td>\n",
       "      <td>0.093041</td>\n",
       "      <td>0.077291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.017894</td>\n",
       "      <td>0.022863</td>\n",
       "      <td>0.046134</td>\n",
       "      <td>-0.027531</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022573</td>\n",
       "      <td>0.015241</td>\n",
       "      <td>-0.007165</td>\n",
       "      <td>0.030543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111131</td>\n",
       "      <td>0.079995</td>\n",
       "      <td>0.045566</td>\n",
       "      <td>0.087192</td>\n",
       "      <td>0.081287</td>\n",
       "      <td>-0.023617</td>\n",
       "      <td>0.034757</td>\n",
       "      <td>0.067262</td>\n",
       "      <td>0.138138</td>\n",
       "      <td>0.099193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.043052</td>\n",
       "      <td>0.084370</td>\n",
       "      <td>-0.064723</td>\n",
       "      <td>0.079333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204311</td>\n",
       "      <td>0.087066</td>\n",
       "      <td>0.150505</td>\n",
       "      <td>0.108832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173530</td>\n",
       "      <td>0.151807</td>\n",
       "      <td>0.092447</td>\n",
       "      <td>0.128092</td>\n",
       "      <td>0.316406</td>\n",
       "      <td>-0.061446</td>\n",
       "      <td>0.289082</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>0.257368</td>\n",
       "      <td>0.211838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.045769</td>\n",
       "      <td>0.028035</td>\n",
       "      <td>0.057566</td>\n",
       "      <td>0.091526</td>\n",
       "      <td>0.037958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602056</td>\n",
       "      <td>0.030222</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.037466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053620</td>\n",
       "      <td>0.041376</td>\n",
       "      <td>0.021975</td>\n",
       "      <td>-0.004069</td>\n",
       "      <td>0.010513</td>\n",
       "      <td>-0.010340</td>\n",
       "      <td>0.046816</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>0.025250</td>\n",
       "      <td>0.024028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         -5P       -4P       -3P       -2P       -1P   0P        1P        2P  \\\n",
       "14  0.025734  0.037940  0.066932  0.019279  0.073621  0.0 -0.076180  0.035905   \n",
       "15  0.029486  0.041007  0.069491 -0.007920  0.059908  0.0 -0.025618  0.023630   \n",
       "16  0.017894  0.022863  0.046134 -0.027531  0.045264  0.0 -0.022573  0.015241   \n",
       "36  0.052927  0.043052  0.084370 -0.064723  0.079333  0.0  0.204311  0.087066   \n",
       "37  0.045769  0.028035  0.057566  0.091526  0.037958  0.0  0.602056  0.030222   \n",
       "\n",
       "          3P        4P  ...      -5pY      -4pY      -3pY      -2pY      -1pY  \\\n",
       "14 -0.005546  0.042921  ...  0.075505  0.071823  0.055032  0.080379 -0.017676   \n",
       "15  0.006274  0.035469  ...  0.095213  0.067924  0.043564  0.083987  0.059089   \n",
       "16 -0.007165  0.030543  ...  0.111131  0.079995  0.045566  0.087192  0.081287   \n",
       "36  0.150505  0.108832  ...  0.173530  0.151807  0.092447  0.128092  0.316406   \n",
       "37  0.024714  0.037466  ...  0.053620  0.041376  0.021975 -0.004069  0.010513   \n",
       "\n",
       "         0pY       1pY       2pY       3pY       4pY  \n",
       "14 -0.038610  0.001892  0.084595  0.052408  0.032714  \n",
       "15 -0.037290  0.042184  0.076801  0.093041  0.077291  \n",
       "16 -0.023617  0.034757  0.067262  0.138138  0.099193  \n",
       "36 -0.061446  0.289082  0.068021  0.257368  0.211838  \n",
       "37 -0.010340  0.046816 -0.002519  0.025250  0.024028  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "## Uncheck to run with saving model\n",
    "# target,pred = train_ml(df, feat_col, target_col, split0, model,'model.joblib')\n",
    "\n",
    "# Run without saving model\n",
    "target,pred = train_ml(df, feat_col, target_col, split0, model)\n",
    "\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_ml_cv( df, # dataframe of values\n",
    "                 feat_col, # feature columns\n",
    "                 target_col,  # target columns\n",
    "                 splits, # splits\n",
    "                 model, # sklearn model\n",
    "                 save = None, # model name to be saved, e.g., 'LR'\n",
    "                 params = {}, # act as kwargs, for model.fit\n",
    "                ):\n",
    "    \n",
    "    \"Cross-validation through the given splits\"\n",
    "    \n",
    "    OOF = []\n",
    "    \n",
    "    for fold, split in enumerate(splits):\n",
    "        # print(f'------ fold: {fold} --------')\n",
    "        \n",
    "        if save is not None: \n",
    "            save = f'models/{save}_{fold}.joblib'\n",
    "            \n",
    "        target, pred = train_ml(df, feat_col, target_col, split, model,save,params=params)\n",
    "        \n",
    "        pred['nfold'] = fold\n",
    "        OOF.append(pred)\n",
    "        \n",
    "    # Concatenate OOF from each fold to a new dataframe\n",
    "    oof = pd.concat(OOF).sort_index()\n",
    "    \n",
    "    \n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = train_ml_cv(df,feat_col,target_col,splits=splits,model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def post_process(pssm_df):\n",
    "    \"Convert neg value to 0, clean non-last three values in position zero, and normalize each position\"\n",
    "    pssm = pssm_df.copy()\n",
    "    pssm = pssm.clip(lower=0)\n",
    "    return clean_zero_normalize(pssm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pssm = post_process(recover_pssm(oof.iloc[0,:-1].sort_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Position\n",
       "-5    1.0\n",
       "-4    1.0\n",
       "-3    1.0\n",
       "-2    1.0\n",
       "-1    1.0\n",
       " 0    1.0\n",
       " 1    1.0\n",
       " 2    1.0\n",
       " 3    1.0\n",
       " 4    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pssm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def post_process_oof(oof_ml,target_col):\n",
    "    oof = oof_ml.copy()\n",
    "    oof[target_col] = oof.apply(lambda r: pd.Series(flatten_pssm(post_process(recover_pssm(r[target_col])),column_wise=False)), axis=1)\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = post_process_oof(oof,target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_score(target,pred,func):\n",
    "    distance = [func(target.loc[i],pred.loc[i,target.columns]) for i in target.index]\n",
    "    return pd.Series(distance,index=target.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_jsd = partial(get_score,func=js_divergence_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_kld = partial(get_score,func=kl_divergence_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pspa_info['jsd'] =get_score_jsd(target,oof)\n",
    "pspa_info['kld'] =get_score_kld(target,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.096463\n",
       "1      0.068114\n",
       "2      0.069720\n",
       "3      0.021238\n",
       "4      0.029262\n",
       "         ...   \n",
       "363    0.055437\n",
       "364    0.038325\n",
       "365    0.034305\n",
       "366    0.039840\n",
       "367    0.076918\n",
       "Name: jsd, Length: 368, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pspa_info['jsd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.611760\n",
       "1      0.838306\n",
       "2      0.940138\n",
       "3      0.199112\n",
       "4      0.412790\n",
       "         ...   \n",
       "363    0.835054\n",
       "364    0.502747\n",
       "365    0.228586\n",
       "366    0.521212\n",
       "367    0.556203\n",
       "Name: kld, Length: 368, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pspa_info['kld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_ce(target_series,pred_series):\n",
    "    return float((-(np.log(recover_pssm(pred_series+EPSILON))*(recover_pssm(target_series))).sum()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_ce = partial(get_score,func=calculate_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pspa_info['ce'] =get_score_ce(target,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.242851\n",
       "1      3.633247\n",
       "2      3.734538\n",
       "3      2.869370\n",
       "4      3.104084\n",
       "         ...   \n",
       "363    3.572266\n",
       "364    3.254591\n",
       "365    2.973783\n",
       "366    3.278089\n",
       "367    3.126652\n",
       "Name: ce, Length: 368, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pspa_info['ce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pspa_info['nfold'] = oof['nfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfold\n",
       "0    0.042169\n",
       "1    0.046005\n",
       "2    0.050073\n",
       "3    0.053140\n",
       "4    0.049842\n",
       "Name: jsd, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pspa_info.groupby('nfold').jsd.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predict_ml(df, # Dataframe that contains features\n",
    "               feat_col, # feature columns\n",
    "               target_col=None,\n",
    "               model_pth = 'model.joblib'\n",
    "              ):\n",
    "    \n",
    "    \"Make predictions based on trained model.\"\n",
    "    \n",
    "    test = df[feat_col]\n",
    "    \n",
    "    model = load(model_pth)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    \n",
    "    pred_df = pd.DataFrame(pred,index=df.index,columns=target_col)\n",
    "    \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncheck below to run if you have model_pth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred2 = predict_ml(X_test,feat_col, target_col, model_pth = 'model.joblib')\n",
    "# pred2.head()\n",
    "## or\n",
    "# predict_ml(df.iloc[split_0[1]],feat_col,'model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
