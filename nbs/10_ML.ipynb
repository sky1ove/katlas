{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML\n",
    "\n",
    "> A collection of machine learning tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# katlas\n",
    "from katlas.data import Data\n",
    "from katlas.pssm import *\n",
    "# from katlas.feature import *\n",
    "from katlas.clustering import *\n",
    "from functools import partial\n",
    "\n",
    "# essentials\n",
    "import pandas as pd, numpy as np\n",
    "from joblib import dump, load\n",
    "import math,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# scipy\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_splits(df: pd.DataFrame, # df contains info for split\n",
    "               stratified: str=None, # colname to make stratified kfold; sampling from different groups\n",
    "               group: str=None, # colname to make group kfold; test and train are from different groups\n",
    "               nfold: int=5,\n",
    "               seed: int=123):\n",
    "    \n",
    "    \"Split samples in a dataframe based on Stratified, Group, or StratifiedGroup Kfold method\"\n",
    "    def _log(colname):\n",
    "        print(kf)\n",
    "        split=splits[0]\n",
    "        print(f'# {colname} in train set: {df.loc[split[0]][colname].unique().shape[0]}')\n",
    "        print(f'# {colname} in test set: {df.loc[split[1]][colname].unique().shape[0]}')\n",
    "        \n",
    "    splits = []\n",
    "    if stratified is not None and group is None:\n",
    "        kf = StratifiedKFold(nfold, shuffle=True, random_state=seed)\n",
    "        for split in kf.split(df.index, df[stratified]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(stratified)\n",
    "        \n",
    "    elif group is not None and stratified is None:\n",
    "        kf = GroupKFold(nfold)\n",
    "        for split in kf.split(df.index, groups=df[group]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(group)\n",
    "        \n",
    "    elif stratified is not None and group is not None:\n",
    "        kf = StratifiedGroupKFold(nfold, shuffle=True, random_state=seed)\n",
    "        for split in kf.split(df.index, groups=df[group], y=df[stratified]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(stratified)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either 'stratified' or 'group' argument must be provided.\")\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_data.ipynb\t       04_feature.ipynb     10_ML.ipynb   models\n",
      "01_utils.ipynb\t       05_plot.ipynb\t    11_DNN.ipynb  nbdev.yml\n",
      "02_pssm.ipynb\t       06_pathway.ipynb     _quarto.yml   styles.css\n",
      "03_hierarchical.ipynb  07_alignment.ipynb   custom.scss\n",
      "03_scoring.ipynb       08_statistics.ipynb  index.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_parquet('paper/kinase_domain/train/pspa_t5.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info=Data.get_kinase_info()\n",
    "\n",
    "# info = info[info.pseudo=='0']\n",
    "\n",
    "# info = info[info.kd_ID.notna()]\n",
    "\n",
    "# subfamily_map = info[['kd_ID','subfamily']].drop_duplicates().set_index('kd_ID')['subfamily']\n",
    "\n",
    "# pspa_info = pd.DataFrame(df.index.tolist(),columns=['kinase'])\n",
    "\n",
    "# pspa_info['subfamily'] = pspa_info.kinase.map(subfamily_map)\n",
    "\n",
    "# splits = get_splits(pspa_info, group='subfamily',nfold=5)\n",
    "\n",
    "# split0 = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # column name of feature and target\n",
    "# feat_col = df.columns[df.columns.str.startswith('T5_')]\n",
    "# target_col = df.columns[~df.columns.isin(feat_col)][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_data(df: pd.DataFrame, # dataframe of values\n",
    "               feat_col: list, # feature columns\n",
    "               target_col: list, # target columns\n",
    "               split: tuple # one of the split in splits\n",
    "               ):\n",
    "    \"Given split tuple, split dataframe into X_train, y_train, X_test, y_test\"\n",
    "    \n",
    "    X_train = df.loc[split[0]][feat_col]\n",
    "    y_train = df.loc[split[0]][target_col]\n",
    "    \n",
    "    X_test = df.loc[split[1]][feat_col]\n",
    "    y_test = df.loc[split[1]][target_col]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = split_data(df,feat_col, target_col, split0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_ml(df, # dataframe of values\n",
    "             feat_col, # feature columns\n",
    "             target_col, # target columns\n",
    "             split, # one split in splits\n",
    "             model,  # a sklearn models\n",
    "             save = None, # file (.joblib) to save, e.g. 'model.joblib'\n",
    "             params={}, # parameters for model.fit from sklearn\n",
    "            ):\n",
    "    \n",
    "    \"Fit and predict using sklearn model format, return target and pred of valid dataset.\"\n",
    "    \n",
    "    # split data\n",
    "    X_train, y_train, X_test, y_test = split_data(df, feat_col, target_col, split)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, **params) # better convert y_train to numpy array and flatten\n",
    "    \n",
    "    if save is not None:\n",
    "        # Save the model to a file\n",
    "        # joblib.dump(model, save)\n",
    "        dump(model, save)\n",
    "        \n",
    "    # Predict train\n",
    "    y_train_pred = model.predict(X_train) # X_test is dataframe, y_pred is numpy array\n",
    "    \n",
    "    # Predict test\n",
    "    y_pred = model.predict(X_test) # X_test is dataframe, y_pred is numpy array\n",
    "\n",
    "    # Make dataframe\n",
    "    y_pred = pd.DataFrame(y_pred,index=y_test.index, columns = y_test.columns)\n",
    "    \n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# ## Uncheck to run with saving model\n",
    "# # target,pred = train_ml(df, feat_col, target_col, split0, model,'model.joblib')\n",
    "\n",
    "# # Run without saving model\n",
    "# target,pred = train_ml(df, feat_col, target_col, split0, model)\n",
    "\n",
    "# pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_ml_cv( df, # dataframe of values\n",
    "                 feat_col, # feature columns\n",
    "                 target_col,  # target columns\n",
    "                 splits, # splits\n",
    "                 model, # sklearn model\n",
    "                 save = None, # model name to be saved, e.g., 'LR'\n",
    "                 params = {}, # act as kwargs, for model.fit\n",
    "                ):\n",
    "    \n",
    "    \"Cross-validation through the given splits\"\n",
    "    \n",
    "    OOF = []\n",
    "    \n",
    "    for fold, split in enumerate(splits):\n",
    "        # print(f'------ fold: {fold} --------')\n",
    "        \n",
    "        if save is not None: \n",
    "            save = f'models/{save}_{fold}.joblib'\n",
    "            \n",
    "        target, pred = train_ml(df, feat_col, target_col, split, model,save,params=params)\n",
    "        \n",
    "        pred['nfold'] = fold\n",
    "        OOF.append(pred)\n",
    "        \n",
    "    # Concatenate OOF from each fold to a new dataframe\n",
    "    oof = pd.concat(OOF).sort_index()\n",
    "    \n",
    "    \n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof = train_ml_cv(df,feat_col,target_col,splits=splits,model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def post_process(pssm_df):\n",
    "    \"Convert neg value to 0, clean non-last three values in position zero, and normalize each position\"\n",
    "    pssm = pssm_df.copy()\n",
    "    pssm = pssm.clip(lower=0)\n",
    "    return clean_zero_normalize(pssm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pssm = post_process(recover_pssm(oof.iloc[0,:-1].sort_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pssm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def post_process_oof(oof_ml,target_col):\n",
    "    oof = oof_ml.copy()\n",
    "    oof[target_col] = oof.apply(lambda r: pd.Series(flatten_pssm(post_process(recover_pssm(r[target_col])),column_wise=False)), axis=1)\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof = post_process_oof(oof,target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_score(target,pred,func):\n",
    "    distance = [func(target.loc[i],pred.loc[i,target.columns]) for i in target.index]\n",
    "    return pd.Series(distance,index=target.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_jsd = partial(get_score,func=js_divergence_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_kld = partial(get_score,func=kl_divergence_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['jsd'] =get_score_jsd(target,oof)\n",
    "# pspa_info['kld'] =get_score_kld(target,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['jsd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['kld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_ce(target_series,pred_series):\n",
    "    return float((-(np.log(recover_pssm(pred_series+EPSILON))*(recover_pssm(target_series))).sum()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_ce = partial(get_score,func=calculate_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['ce'] =get_score_ce(target,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['ce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['nfold'] = oof['nfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info.groupby('nfold').jsd.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predict_ml(df, # Dataframe that contains features\n",
    "               feat_col, # feature columns\n",
    "               target_col=None,\n",
    "               model_pth = 'model.joblib'\n",
    "              ):\n",
    "    \n",
    "    \"Make predictions based on trained model.\"\n",
    "    \n",
    "    test = df[feat_col]\n",
    "    \n",
    "    model = load(model_pth)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    \n",
    "    pred_df = pd.DataFrame(pred,index=df.index,columns=target_col)\n",
    "    \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncheck below to run if you have model_pth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred2 = predict_ml(X_test,feat_col, target_col, model_pth = 'model.joblib')\n",
    "# pred2.head()\n",
    "## or\n",
    "# predict_ml(df.iloc[split_0[1]],feat_col,'model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
