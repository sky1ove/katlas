{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0491f762",
   "metadata": {},
   "source": [
    "# Train ML\n",
    "\n",
    "> A collection of machine learning tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e20b70",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A collection of utilities for training, evaluating, and deploying scikit-learn models for kinase substrate specificity prediction.\n",
    "\n",
    "---\n",
    "\n",
    "**Data Splitting**\n",
    "\n",
    "`get_splits` - Creates cross-validation splits using stratified, grouped, or stratified-grouped KFold methods. This ensures proper data separation to avoid data leakage (e.g., keeping kinases from the same subfamily in the same fold).\n",
    "\n",
    "```python\n",
    "splits = get_splits(\n",
    "    df=pspa_info,        # DataFrame containing metadata for splitting\n",
    "    stratified=None,     # column name for stratified sampling (samples from different strata in each fold)\n",
    "    group='subfamily',   # column name for group splitting (train/test never share groups)\n",
    "    nfold=5,             # number of cross-validation folds\n",
    "    seed=123,            # random seed for reproducibility\n",
    ")\n",
    "```\n",
    "\n",
    "`split_data` - Splits a dataframe into train/test features and targets based on a single split tuple from `get_splits`.\n",
    "\n",
    "```python\n",
    "X_train, y_train, X_test, y_test = split_data(\n",
    "    df=df,               # full DataFrame with features and targets\n",
    "    feat_col=feat_col,   # list of feature column names (e.g., T5 embeddings)\n",
    "    target_col=target_col,  # list of target column names (e.g., PSSM values)\n",
    "    split=splits[0],     # tuple of (train_indices, test_indices)\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Model Training**\n",
    "\n",
    "`train_ml` - Fits a single sklearn model on one train/test split and returns predictions on the test set. Optionally saves the trained model.\n",
    "\n",
    "```python\n",
    "y_test, y_pred = train_ml(\n",
    "    df=df,                    # DataFrame with features and targets\n",
    "    feat_col=feat_col,        # feature column names\n",
    "    target_col=target_col,    # target column names\n",
    "    split=splits[0],          # single split tuple (train_idx, test_idx)\n",
    "    model=LinearRegression(), # any sklearn-compatible model\n",
    "    save='models/lr_fold0.joblib',  # path to save model (None to skip)\n",
    "    params={},                # extra kwargs passed to model.fit()\n",
    ")\n",
    "```\n",
    "\n",
    "`train_ml_cv` - Performs full cross-validation across all splits, returning out-of-fold (OOF) predictions for the entire dataset.\n",
    "\n",
    "```python\n",
    "oof = train_ml_cv(\n",
    "    df=df,                    # DataFrame with features and targets\n",
    "    feat_col=feat_col,        # feature column names\n",
    "    target_col=target_col,    # target column names\n",
    "    splits=splits,            # list of split tuples from get_splits\n",
    "    model=Ridge(alpha=1.0),   # sklearn model (re-instantiated each fold)\n",
    "    save='ridge',             # base name for saved models (becomes ridge_0.joblib, etc.)\n",
    "    params={},                # extra kwargs for model.fit()\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Post-Processing**\n",
    "\n",
    "`post_process` - Cleans raw PSSM predictions by clipping negatives to zero, cleaning position zero, and normalizing each position to sum to 1.\n",
    "\n",
    "```python\n",
    "pssm_clean = post_process(\n",
    "    pssm_df=raw_pssm,    # raw PSSM DataFrame (positions Ã— amino acids)\n",
    ")\n",
    "```\n",
    "\n",
    "`post_process_oof` - Applies `post_process` to all rows in an OOF prediction DataFrame.\n",
    "\n",
    "```python\n",
    "oof_clean = post_process_oof(\n",
    "    oof_ml=oof,          # OOF DataFrame from train_ml_cv\n",
    "    target_col=target_col,  # target column names to process\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Scoring**\n",
    "\n",
    "`get_score` - Computes a per-sample score between target and prediction using a custom function.\n",
    "\n",
    "```python\n",
    "scores = get_score(\n",
    "    target=df[target_col],  # ground truth DataFrame\n",
    "    pred=oof[target_col],   # predictions DataFrame\n",
    "    func=js_divergence_flat,  # scoring function (target_row, pred_row) -> float\n",
    ")\n",
    "```\n",
    "\n",
    "**Convenience partials** - Pre-configured scorers:\n",
    "\n",
    "```python\n",
    "jsd_scores = get_score_jsd(target=df[target_col], pred=oof)  # Jensen-Shannon divergence\n",
    "kld_scores = get_score_kld(target=df[target_col], pred=oof)  # KL divergence\n",
    "ce_scores  = get_score_ce(target=df[target_col], pred=oof)   # Cross-entropy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Inference**\n",
    "\n",
    "`predict_ml` - Loads a saved model and generates predictions on new data.\n",
    "\n",
    "```python\n",
    "predictions = predict_ml(\n",
    "    df=new_data,              # DataFrame containing features\n",
    "    feat_col=feat_col,        # feature column names (must match training)\n",
    "    target_col=target_col,    # column names for output DataFrame\n",
    "    model_pth='models/ridge_0.joblib',  # path to saved model\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Typical Workflow**\n",
    "\n",
    "```python\n",
    "# 1. Prepare splits (group by subfamily to prevent leakage)\n",
    "splits = get_splits(df=info, group='subfamily', nfold=5)\n",
    "\n",
    "# 2. Train with cross-validation\n",
    "oof = train_ml_cv(df=df, feat_col=feat_col, target_col=target_col, \n",
    "                  splits=splits, model=Ridge(), save='ridge')\n",
    "\n",
    "# 3. Post-process predictions\n",
    "oof = post_process_oof(oof_ml=oof, target_col=target_col)\n",
    "\n",
    "# 4. Evaluate\n",
    "info['jsd'] = get_score_jsd(target=df[target_col], pred=oof)\n",
    "print(f\"Mean JSD: {info.groupby('nfold').jsd.mean()}\")\n",
    "\n",
    "# 5. Deploy\n",
    "pred = predict_ml(df=test_df, feat_col=feat_col, target_col=target_col,\n",
    "                  model_pth='models/ridge_0.joblib')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db70840b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d702b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# katlas\n",
    "from katlas.data import Data\n",
    "from katlas.pssm.core import *\n",
    "from katlas.pssm.compare import *\n",
    "# from katlas.feature import *\n",
    "from functools import partial\n",
    "\n",
    "# essentials\n",
    "import pandas as pd, numpy as np\n",
    "from joblib import dump, load\n",
    "import math,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# scipy\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421b56d",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ef51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_splits(df: pd.DataFrame, # df contains info for split\n",
    "               stratified: str=None, # colname to make stratified kfold; sampling from different groups\n",
    "               group: str=None, # colname to make group kfold; test and train are from different groups\n",
    "               nfold: int=5,\n",
    "               seed: int=123):\n",
    "    \n",
    "    \"Split samples in a dataframe based on Stratified, Group, or StratifiedGroup Kfold method\"\n",
    "    def _log(colname):\n",
    "        print(kf)\n",
    "        split=splits[0]\n",
    "        print(f'# {colname} in train set: {df.loc[split[0]][colname].unique().shape[0]}')\n",
    "        print(f'# {colname} in test set: {df.loc[split[1]][colname].unique().shape[0]}')\n",
    "        \n",
    "    splits = []\n",
    "    if stratified is not None and group is None:\n",
    "        kf = StratifiedKFold(nfold, shuffle=True, random_state=seed)\n",
    "        for split in kf.split(df.index, df[stratified]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(stratified)\n",
    "        \n",
    "    elif group is not None and stratified is None:\n",
    "        kf = GroupKFold(nfold)\n",
    "        for split in kf.split(df.index, groups=df[group]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(group)\n",
    "        \n",
    "    elif stratified is not None and group is not None:\n",
    "        kf = StratifiedGroupKFold(nfold, shuffle=True, random_state=seed)\n",
    "        for split in kf.split(df.index, groups=df[group], y=df[stratified]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        _log(stratified)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either 'stratified' or 'group' argument must be provided.\")\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ccd80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_data.ipynb\t     02e_pssm_compare.ipynb  07_pathway.ipynb\t   custom.scss\r\n",
      "01_utils.ipynb\t     03_scoring.ipynb\t     10_ML.ipynb\t   index.ipynb\r\n",
      "02a_pssm_core.ipynb  04_clustering.ipynb     11_DNN.ipynb\t   models\r\n",
      "02b_pssm_plot.ipynb  04b_hierarchical.ipynb  _08_statistics.ipynb  nbdev.yml\r\n",
      "02c_pssm_lo.ipynb    05_feature.ipynb\t     _quarto.yml\t   styles.css\r\n",
      "02d_pssm_pspa.ipynb  06_plot.ipynb\t     _test.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_parquet('paper/kinase_domain/train/pspa_t5.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af12689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info=Data.get_kinase_info()\n",
    "\n",
    "# info = info[info.pseudo=='0']\n",
    "\n",
    "# info = info[info.kd_ID.notna()]\n",
    "\n",
    "# subfamily_map = info[['kd_ID','subfamily']].drop_duplicates().set_index('kd_ID')['subfamily']\n",
    "\n",
    "# pspa_info = pd.DataFrame(df.index.tolist(),columns=['kinase'])\n",
    "\n",
    "# pspa_info['subfamily'] = pspa_info.kinase.map(subfamily_map)\n",
    "\n",
    "# splits = get_splits(pspa_info, group='subfamily',nfold=5)\n",
    "\n",
    "# split0 = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7723e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # column name of feature and target\n",
    "# feat_col = df.columns[df.columns.str.startswith('T5_')]\n",
    "# target_col = df.columns[~df.columns.isin(feat_col)][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d38c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d459df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_data(df: pd.DataFrame, # dataframe of values\n",
    "               feat_col: list, # feature columns\n",
    "               target_col: list, # target columns\n",
    "               split: tuple # one of the split in splits\n",
    "               ):\n",
    "    \"Given split tuple, split dataframe into X_train, y_train, X_test, y_test\"\n",
    "    \n",
    "    X_train = df.loc[split[0]][feat_col]\n",
    "    y_train = df.loc[split[0]][target_col]\n",
    "    \n",
    "    X_test = df.loc[split[1]][feat_col]\n",
    "    y_test = df.loc[split[1]][target_col]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c510648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = split_data(df,feat_col, target_col, split0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54435d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da162751",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_ml(df, # dataframe of values\n",
    "             feat_col, # feature columns\n",
    "             target_col, # target columns\n",
    "             split, # one split in splits\n",
    "             model,  # a sklearn models\n",
    "             save = None, # file (.joblib) to save, e.g. 'model.joblib'\n",
    "             params=None, # dict parameters for model.fit from sklearn\n",
    "            ):\n",
    "    \n",
    "    \"Fit and predict using sklearn model format, return target and pred of valid dataset.\"\n",
    "    \n",
    "    # split data\n",
    "    X_train, y_train, X_test, y_test = split_data(df, feat_col, target_col, split)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, **(params or {})) # better convert y_train to numpy array and flatten\n",
    "    \n",
    "    if save is not None:\n",
    "        # Save the model to a file\n",
    "        # joblib.dump(model, save)\n",
    "        dump(model, save)\n",
    "        \n",
    "    # Predict train\n",
    "    y_train_pred = model.predict(X_train) # X_test is dataframe, y_pred is numpy array\n",
    "    \n",
    "    # Predict test\n",
    "    y_pred = model.predict(X_test) # X_test is dataframe, y_pred is numpy array\n",
    "\n",
    "    # Make dataframe\n",
    "    y_pred = pd.DataFrame(y_pred,index=y_test.index, columns = y_test.columns)\n",
    "    \n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb76da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# ## Uncheck to run with saving model\n",
    "# # target,pred = train_ml(df, feat_col, target_col, split0, model,'model.joblib')\n",
    "\n",
    "# # Run without saving model\n",
    "# target,pred = train_ml(df, feat_col, target_col, split0, model)\n",
    "\n",
    "# pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01269a",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_ml_cv( df, # dataframe of values\n",
    "                 feat_col, # feature columns\n",
    "                 target_col,  # target columns\n",
    "                 splits, # splits\n",
    "                 model, # sklearn model\n",
    "                 save = None, # model name to be saved, e.g., 'LR'\n",
    "                 params = None, # act as kwargs, for model.fit\n",
    "                ):\n",
    "    \n",
    "    \"Cross-validation through the given splits\"\n",
    "    \n",
    "    OOF = []\n",
    "    \n",
    "    for fold, split in enumerate(splits):\n",
    "        # print(f'------ fold: {fold} --------')\n",
    "        \n",
    "        if save is not None: \n",
    "            save = f'models/{save}_{fold}.joblib'\n",
    "            \n",
    "        target, pred = train_ml(df, feat_col, target_col, split, model,save,params=params)\n",
    "        \n",
    "        pred['nfold'] = fold\n",
    "        OOF.append(pred)\n",
    "        \n",
    "    # Concatenate OOF from each fold to a new dataframe\n",
    "    oof = pd.concat(OOF).sort_index()\n",
    "    \n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff55f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof = train_ml_cv(df,feat_col,target_col,splits=splits,model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60427a",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76508f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def post_process(pssm_df):\n",
    "    \"Convert neg value to 0, clean non-last three values in position zero, and normalize each position\"\n",
    "    pssm = pssm_df.copy()\n",
    "    pssm = pssm.clip(lower=0)\n",
    "    return clean_zero_normalize(pssm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b737daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pssm = post_process(recover_pssm(oof.iloc[0,:-1].sort_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dece46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pssm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def post_process_oof(oof_ml,target_col):\n",
    "    oof = oof_ml.copy()\n",
    "    oof[target_col] = oof.apply(lambda r: pd.Series(flatten_pssm(post_process(recover_pssm(r[target_col])),column_wise=False)), axis=1)\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof = post_process_oof(oof,target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72142c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_score(target,pred,func):\n",
    "    distance = [func(target.loc[i],pred.loc[i,target.columns]) for i in target.index]\n",
    "    return pd.Series(distance,index=target.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874abcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_jsd = partial(get_score,func=js_divergence_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_kld = partial(get_score,func=kl_divergence_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['jsd'] =get_score_jsd(target,oof)\n",
    "# pspa_info['kld'] =get_score_kld(target,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247926ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['jsd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe106466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['kld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff707eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_ce(target_series,pred_series):\n",
    "    return float((-(np.log(recover_pssm(pred_series+EPSILON))*(recover_pssm(target_series))).sum()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_score_ce = partial(get_score,func=calculate_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b51531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['ce'] =get_score_ce(target,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695deef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['ce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info['nfold'] = oof['nfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspa_info.groupby('nfold').jsd.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e9ef68",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predict_ml(df, # Dataframe that contains features\n",
    "               feat_col, # feature columns\n",
    "               target_col=None,\n",
    "               model_pth = 'model.joblib'\n",
    "              ):\n",
    "    \n",
    "    \"Make predictions based on trained model.\"\n",
    "    \n",
    "    test = df[feat_col]\n",
    "    \n",
    "    model = load(model_pth)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    \n",
    "    pred_df = pd.DataFrame(pred,index=df.index,columns=target_col)\n",
    "    \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b52e4",
   "metadata": {},
   "source": [
    "Uncheck below to run if you have model_pth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred2 = predict_ml(X_test,feat_col, target_col, model_pth = 'model.joblib')\n",
    "# pred2.head()\n",
    "## or\n",
    "# predict_ml(df.iloc[split_0[1]],feat_col,'model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c699f2c",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296036b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
