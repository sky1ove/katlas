{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "> In this module, we develop trainers of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import sys\n",
    "sys.path.append(\"/notebooks/katlas\")\n",
    "from nbdev.showdoc import *\n",
    "%matplotlib inline\n",
    "from katlas.core import Data\n",
    "from katlas.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastbook import *\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def xgb_trainer(df,\n",
    "                feature_col,\n",
    "                target_col,\n",
    "                test_index=None,\n",
    "                xgb_params = { \n",
    "                            'max_depth':7, #from 4 to 7\n",
    "                            'learning_rate':0.001, #from 0.001\n",
    "                            'subsample':0.8,\n",
    "                            'colsample_bytree':1, # from 0.2 to 1, because need to take all features\n",
    "                            'eval_metric':'rmse',\n",
    "                            'objective':'reg:squarederror',\n",
    "                            'tree_method':'gpu_hist',\n",
    "                            'predictor':'gpu_predictor',\n",
    "                            'random_state':123\n",
    "                        },\n",
    "                model_file='xgb_model.bin',\n",
    "                split_seed = 123, # seed of random split\n",
    "               ):\n",
    "    \n",
    "    X = df[feature_col]\n",
    "    y = df[target_col]\n",
    "    \n",
    "    print(f'xgb params is: {xgb_params}')\n",
    "    \n",
    "    if test_index is None:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=split_seed)\n",
    "    else:\n",
    "        X_train,y_train = X.loc[~X.index.isin(test_index)],y.loc[~X.index.isin(test_index)]\n",
    "        X_test, y_test = X.loc[test_index],y.loc[test_index]\n",
    "\n",
    "        \n",
    "    print(X_train.shape,y_train.shape,X_test.shape, y_test.shape)\n",
    "    print(y_test.index)\n",
    "    #prepare matrix for xgb\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test, y_test)\n",
    "    \n",
    "    model = xgb.train(xgb_params, \n",
    "            dtrain=dtrain,\n",
    "            evals=[(dtrain,'train'),(dtest,'valid')],\n",
    "            num_boost_round=9999,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,)\n",
    "    \n",
    "    # Save the model\n",
    "    path = Path(model_file)\n",
    "    \n",
    "    # Make a directory if not exists\n",
    "    path.parent.mkdir(exist_ok=True)\n",
    "        \n",
    "    model.save_model(model_file)\n",
    "    print(f'Model saved to {model_file}')\n",
    "    \n",
    "    pred = model.predict(dtest)\n",
    "    spearman_corr, _ = spearmanr(y_test, pred)\n",
    "    print(f'Spearman correlation: {spearman_corr:.2f}')\n",
    "    pearson_corr, p_value = pearsonr(y_test, pred)\n",
    "    print(f'Pearson correlation: {pearson_corr:.2f}')\n",
    "    out = np.vstack([np.ravel(y_test),np.ravel(pred)]).T\n",
    "    pred_df = pd.DataFrame(out,index=y_test.index, columns = ['label','pred'] )\n",
    "    pred_df['pred'] = pred\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, pred)\n",
    "    ax.set_xlabel('True values')\n",
    "    ax.set_ylabel('Predicted values')\n",
    "    ax.set_title('Scatter plot of true versus predicted values')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    dd = model.get_score(importance_type='gain')\n",
    "    gain = pd.DataFrame({'feature':dd.keys(),f'gain_importance':dd.values()}).set_index('feature').sort_values(by='gain_importance',ascending=False)\n",
    "    gain[:10].plot.barh()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        \n",
    "    dd = model.get_score(importance_type='weight')\n",
    "    weight = pd.DataFrame({'feature':dd.keys(),f'weight_importance':dd.values()}).set_index('feature').sort_values(by='weight_importance',ascending=False)\n",
    "    weight[:10].plot.barh()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return pred_df, gain, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### xgb_trainer\n",
       "\n",
       ">      xgb_trainer (df, feature_col, target_col, test_index=None,\n",
       ">                   xgb_params={'max_depth': 7, 'learning_rate': 0.001,\n",
       ">                   'subsample': 0.8, 'colsample_bytree': 1, 'eval_metric':\n",
       ">                   'rmse', 'objective': 'reg:squarederror', 'tree_method':\n",
       ">                   'gpu_hist', 'predictor': 'gpu_predictor', 'random_state':\n",
       ">                   123}, model_file='xgb_model.bin', split_seed=123)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df |  |  |  |\n",
       "| feature_col |  |  |  |\n",
       "| target_col |  |  |  |\n",
       "| test_index | NoneType | None |  |\n",
       "| xgb_params | dict | {'max_depth': 7, 'learning_rate': 0.001, 'subsample': 0.8, 'colsample_bytree': 1, 'eval_metric': 'rmse', 'objective': 'reg:squarederror', 'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'random_state': 123} |  |\n",
       "| model_file | str | xgb_model.bin |  |\n",
       "| split_seed | int | 123 | seed of random split |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### xgb_trainer\n",
       "\n",
       ">      xgb_trainer (df, feature_col, target_col, test_index=None,\n",
       ">                   xgb_params={'max_depth': 7, 'learning_rate': 0.001,\n",
       ">                   'subsample': 0.8, 'colsample_bytree': 1, 'eval_metric':\n",
       ">                   'rmse', 'objective': 'reg:squarederror', 'tree_method':\n",
       ">                   'gpu_hist', 'predictor': 'gpu_predictor', 'random_state':\n",
       ">                   123}, model_file='xgb_model.bin', split_seed=123)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df |  |  |  |\n",
       "| feature_col |  |  |  |\n",
       "| target_col |  |  |  |\n",
       "| test_index | NoneType | None |  |\n",
       "| xgb_params | dict | {'max_depth': 7, 'learning_rate': 0.001, 'subsample': 0.8, 'colsample_bytree': 1, 'eval_metric': 'rmse', 'objective': 'reg:squarederror', 'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'random_state': 123} |  |\n",
       "| model_file | str | xgb_model.bin |  |\n",
       "| split_seed | int | 123 | seed of random split |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(xgb_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def xgb_predict(df, # a dataframe that contains ID and features for prediction\n",
    "                feature_col, #feature column name\n",
    "                ID_col = \"ID\", #ID column name\n",
    "                model_file='xgb_model.bin'):\n",
    "    # Load the XGBoost model\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(model_file)\n",
    "    \n",
    "    # Prepare data for prediction\n",
    "    X = df[feature_col]\n",
    "    dtest = xgb.DMatrix(X)\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = model.predict(dtest)\n",
    "    \n",
    "    # Combine predictions with IDs into a DataFrame\n",
    "    result_df = pd.DataFrame({ID_col: df[ID_col], 'preds': preds})\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### xgb_predict\n",
       "\n",
       ">      xgb_predict (df, feature_col, ID_col='ID', model_file='xgb_model.bin')\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df |  |  | a dataframe that contains ID and features for prediction |\n",
       "| feature_col |  |  | feature column name |\n",
       "| ID_col | str | ID | ID column name |\n",
       "| model_file | str | xgb_model.bin |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### xgb_predict\n",
       "\n",
       ">      xgb_predict (df, feature_col, ID_col='ID', model_file='xgb_model.bin')\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df |  |  | a dataframe that contains ID and features for prediction |\n",
       "| feature_col |  |  | feature column name |\n",
       "| ID_col | str | ID | ID column name |\n",
       "| model_file | str | xgb_model.bin |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(xgb_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/nbdev/export.py:54: UserWarning: Notebook '/notebooks/katlas/nbs/tutorial_01_kinase_feature.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n",
      "/usr/local/lib/python3.9/dist-packages/nbdev/export.py:54: UserWarning: Notebook '/notebooks/katlas/nbs/tutorial_02_aa_feature.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n",
      "/usr/local/lib/python3.9/dist-packages/nbdev/export.py:54: UserWarning: Notebook '/notebooks/katlas/nbs/tutorial_03a_target_transform.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n",
      "/usr/local/lib/python3.9/dist-packages/nbdev/export.py:54: UserWarning: Notebook '/notebooks/katlas/nbs/tutorial_04_train.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
