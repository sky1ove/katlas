{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60bb6a2",
   "metadata": {},
   "source": [
    "# Feature\n",
    "\n",
    "> A collection of tools to extract features from SMILES, proteins, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0806fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b9cc9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This module provides tools to extract features from SMILES (chemical compounds) and protein sequences for machine learning applications.\n",
    "\n",
    "---\n",
    "\n",
    "**Utility Functions**\n",
    "\n",
    "`remove_hi_corr(df, thr)` - Removes highly correlated features from a DataFrame based on Pearson correlation threshold. Useful for reducing multicollinearity before modeling.\n",
    "\n",
    "```python\n",
    "df_cleaned = remove_hi_corr(\n",
    "    df=my_features,  # DataFrame with features as columns\n",
    "    thr=0.98,        # correlation threshold above which to drop columns\n",
    ")\n",
    "```\n",
    "\n",
    "`preprocess(df, thr)` - Combines zero-variance removal with correlation filtering. Drops columns with no variance (e.g., constant values) and highly correlated features.\n",
    "\n",
    "```python\n",
    "df_processed = preprocess(\n",
    "    df=my_features,  # DataFrame with features\n",
    "    thr=0.98,        # correlation threshold\n",
    ")\n",
    "```\n",
    "\n",
    "`standardize(df)` - Standardizes features to zero mean and unit variance using sklearn's StandardScaler.\n",
    "\n",
    "```python\n",
    "df_scaled = standardize(\n",
    "    df=my_features,  # DataFrame to standardize\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Compound Features (SMILES)**\n",
    "\n",
    "`get_rdkit(SMILES)` - Extracts ~200 RDKit molecular descriptors from a SMILES string.\n",
    "\n",
    "```python\n",
    "features = get_rdkit(\n",
    "    SMILES=\"CC(=O)O\",  # SMILES representation of molecule\n",
    ")\n",
    "```\n",
    "\n",
    "`get_rdkit_3d(SMILES)` - Extracts 3D molecular descriptors after generating a conformer using ETKDG embedding.\n",
    "\n",
    "```python\n",
    "features_3d = get_rdkit_3d(\n",
    "    SMILES=\"CC(=O)O\",  # SMILES representation of molecule\n",
    ")\n",
    "```\n",
    "\n",
    "`get_rdkit_df(df, col, postprocess)` - Batch extracts RDKit features (2D + 3D) from a DataFrame column containing SMILES. Optionally removes redundant features and standardizes.\n",
    "\n",
    "```python\n",
    "rdkit_features = get_rdkit_df(\n",
    "    df=compounds_df,   # DataFrame containing SMILES\n",
    "    col='SMILES',      # column name with SMILES strings\n",
    "    postprocess=True,  # remove redundant columns & standardize\n",
    ")\n",
    "```\n",
    "\n",
    "`get_morgan(df, col, radius)` - Generates 2048-bit Morgan fingerprints (circular fingerprints) from SMILES.\n",
    "\n",
    "```python\n",
    "morgan_fps = get_morgan(\n",
    "    df=compounds_df,  # DataFrame containing SMILES\n",
    "    col='SMILES',     # column name with SMILES strings\n",
    "    radius=3,         # radius for Morgan fingerprint\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Protein Sequence Features - One-Hot Encoding**\n",
    "\n",
    "`onehot_encode(sequences, transform_colname, n)` - Converts amino acid sequences to one-hot encoded matrix.\n",
    "\n",
    "```python\n",
    "encoded = onehot_encode(\n",
    "    sequences=df['site_seq'],  # iterable of AA sequences\n",
    "    transform_colname=True,    # convert column names to position format\n",
    "    n=20,                      # number of standard amino acids\n",
    ")\n",
    "```\n",
    "\n",
    "`onehot_encode_df(df, seq_col)` - Convenience wrapper for one-hot encoding from a DataFrame.\n",
    "\n",
    "```python\n",
    "encoded = onehot_encode_df(\n",
    "    df=my_df,            # DataFrame with sequences\n",
    "    seq_col='site_seq',  # column name containing sequences\n",
    ")\n",
    "```\n",
    "\n",
    "`filter_range_columns(df, low, high)` - Filters one-hot encoded columns to specific sequence positions (e.g., -10 to +10 around a site).\n",
    "\n",
    "```python\n",
    "filtered = filter_range_columns(\n",
    "    df=onehot_df,  # one-hot encoded DataFrame with position+AA column names\n",
    "    low=-10,       # minimum position to include\n",
    "    high=10,       # maximum position to include\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Clustering**\n",
    "\n",
    "`run_kmeans(onehot, n, seed)` - Performs K-means clustering on encoded data and returns cluster assignments.\n",
    "\n",
    "```python\n",
    "clusters = run_kmeans(\n",
    "    onehot=encoded_df,  # one-hot or other feature matrix\n",
    "    n=10,               # number of clusters\n",
    "    seed=42,            # random seed for reproducibility\n",
    ")\n",
    "```\n",
    "\n",
    "`get_clusters_elbow(encoded_data, max_cluster, interval)` - Plots the elbow curve (WCSS vs. # clusters) to help choose optimal k.\n",
    "\n",
    "```python\n",
    "get_clusters_elbow(\n",
    "    encoded_data=onehot_df,  # feature matrix for clustering\n",
    "    max_cluster=400,         # maximum clusters to test\n",
    "    interval=50,             # step size between cluster counts\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Protein Language Model Embeddings**\n",
    "\n",
    "`get_esm(df, col, model_name)` - Extracts ESM2 embeddings (mean-pooled) from protein sequences. Requires GPU.\n",
    "\n",
    "```python\n",
    "esm_features = get_esm(\n",
    "    df=kinase_df,                      # DataFrame with protein sequences\n",
    "    col='sequence',                    # column name with AA sequences\n",
    "    model_name='esm2_t33_650M_UR50D',  # ESM2 model variant\n",
    ")\n",
    "```\n",
    "\n",
    "`get_t5(df, col)` - Extracts ProtT5-XL-UniRef50 embeddings from protein sequences.\n",
    "\n",
    "```python\n",
    "t5_features = get_t5(\n",
    "    df=kinase_df,       # DataFrame with protein sequences\n",
    "    col='sequence',     # column name with AA sequences\n",
    ")\n",
    "```\n",
    "\n",
    "`get_t5_bfd(df, col)` - Extracts ProtT5-XL-BFD embeddings (trained on Big Fantastic Database).\n",
    "\n",
    "```python\n",
    "t5bfd_features = get_t5_bfd(\n",
    "    df=kinase_df,       # DataFrame with protein sequences\n",
    "    col='sequence',     # column name with AA sequences\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc132c4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff79e13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m",
      "\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, StandardScaler",
      "\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Rdkit\u001b[39;00m",
      "\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrdkit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chem",
      "\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrdkit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mChem\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Descriptors, Descriptors3D, AllChem, rdFingerprintGenerator",
      "\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Clustering\u001b[39;00m",
      "",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import pandas as pd, numpy as np\n",
    "import torch, re, gc\n",
    "from tqdm.notebook import tqdm; tqdm.pandas()\n",
    "from katlas.data import Data\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Descriptors3D, AllChem, rdFingerprintGenerator\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7575e",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773551a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e955b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_hi_corr(df: pd.DataFrame, \n",
    "                   thr: float=0.98 # threshold\n",
    "                   ):\n",
    "    \"Remove highly correlated features in a dataframe given a pearson threshold\"\n",
    "    \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr(numeric_only=True).abs()\n",
    "    \n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find index of feature columns with correlation greater than threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > thr)]\n",
    "    \n",
    "    # Drop features \n",
    "    df = df.drop(to_drop, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c3851",
   "metadata": {},
   "source": [
    "`remove_hi_corr` is a function to remove highly correlated features based on threshold of Pearson correlation between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb74811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = Data.get_aa_rdkit()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227faebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hi_corr(df,thr=0.9).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def preprocess(df: pd.DataFrame,\n",
    "               thr: float=0.98):\n",
    "    \n",
    "    \"Remove features with no variance, and highly correlated features based on threshold\"\n",
    "    \n",
    "    col_ori = df.columns\n",
    "    df = df.loc[:,df.std() != 0].copy()\n",
    "    df = remove_hi_corr(df, thr)\n",
    "    dropping_col = set(col_ori) - set(df.columns)\n",
    "    print(f'removing columns: {dropping_col}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32b111",
   "metadata": {},
   "source": [
    "This function is similar to `remove_hi_corr`, but can additionaly remove features of zero variance (e.g., 1 across all samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ce03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(df,thr=0.9).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a58993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def standardize(df): \n",
    "    \"Standardize features from a df\"\n",
    "    return StandardScaler().fit_transform(df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde53be",
   "metadata": {},
   "source": [
    "## Compound features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171fb92",
   "metadata": {},
   "source": [
    "### RDKit descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92612fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_rdkit(SMILES):\n",
    "    \"\"\"\n",
    "    Extract chemical features from SMILES\n",
    "    Reference: https://greglandrum.github.io/rdkit-blog/posts/2022-12-23-descriptor-tutorial.html\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(SMILES)\n",
    "    return Descriptors.CalcMolDescriptors(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_rdkit_3d(SMILES):\n",
    "    \"\"\"\n",
    "    Extract 3d features from SMILES\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(SMILES)\n",
    "    mol = Chem.AddHs(mol)\n",
    "    AllChem.EmbedMolecule(mol, AllChem.ETKDG())\n",
    "    AllChem.UFFOptimizeMolecule(mol)\n",
    "    return Descriptors3D.CalcMolDescriptors3D(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19835f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_rdkit_all(SMILES):\n",
    "    \"Extract chemical features and 3d features from SMILES\"\n",
    "    feat = get_rdkit(SMILES)\n",
    "    feat_3d = get_rdkit_3d(SMILES)\n",
    "    return feat|feat_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593167e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_rdkit_df(df,\n",
    "                 col, # column of SMILES\n",
    "                 postprocess=True, # remove redundant columns and standardize features for dimension reduction\n",
    "                 ):\n",
    "    \"Extract rdkit features (including 3d) from SMILES in a df\"\n",
    "    out = df[col].apply(get_rdkit_all).apply(pd.Series)\n",
    "\n",
    "    if postprocess:\n",
    "        out = preprocess(out) # remove redundant\n",
    "        out = standardize(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da09d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = Data.get_aa_info()\n",
    "aa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50479f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_rdkit = get_rdkit_df(aa, 'SMILES')\n",
    "aa_rdkit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9345d8",
   "metadata": {},
   "source": [
    "### Morgan fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_morgan(df: pd.DataFrame, # a dataframe that contains smiles\n",
    "               col: str = \"SMILES\", # colname of smile\n",
    "               radius=3\n",
    "              ):\n",
    "    \"Get 2048 morgan fingerprint (binary feature) from smiles in a dataframe\"\n",
    "    mols = [Chem.MolFromSmiles(smi) for smi in df[col]]\n",
    "\n",
    "    mfpgen = rdFingerprintGenerator.GetMorganGenerator(radius=radius,fpSize=2048)\n",
    "    morgan_fps = [mfpgen.GetFingerprint(mol) for mol in mols]\n",
    "    \n",
    "    fp_df = pd.DataFrame(np.array(morgan_fps), index=df.index)\n",
    "    fp_df.columns = \"morgan_\" + fp_df.columns.astype(str)\n",
    "    return fp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05734de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_morgan = get_morgan(aa, 'SMILES')\n",
    "aa_morgan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_morgan = get_morgan(aa, 'SMILES')\n",
    "aa_morgan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc9d985",
   "metadata": {},
   "source": [
    "## Protein sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf08f1",
   "metadata": {},
   "source": [
    "### Onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0589ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def onehot_encode(sequences, transform_colname=True, n=20):\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    encoded_array = encoder.fit_transform([list(seq) for seq in sequences])\n",
    "    colnames = [x[1:] for x in encoder.get_feature_names_out()]\n",
    "    if transform_colname:\n",
    "        colnames = [f\"{int(item.split('_', 1)[0]) - n}{item.split('_', 1)[1]}\" for item in colnames]\n",
    "    encoded_df = pd.DataFrame(encoded_array)\n",
    "    encoded_df.columns=colnames\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def onehot_encode_df(df,seq_col='site_seq', **kwargs):\n",
    "    return onehot_encode(df[seq_col],**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=Data.get_combine_site_psp_ochoa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf854b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = onehot_encode_df(df_k, seq_col='site_seq')\n",
    "onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a36aed",
   "metadata": {},
   "source": [
    "### Kemans of onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2244e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_kmeans(onehot,n=2,seed=42):\n",
    "    \"Take onehot encoded and regurn the cluster number.\"\n",
    "    kmeans = KMeans(n_clusters=n, random_state=seed,n_init='auto')\n",
    "    return kmeans.fit_predict(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_kmeans(onehot.head(100),n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8091f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_range_columns(df, # df need to have column names of position + aa\n",
    "                         low=-10,high=10):\n",
    "    positions = df.columns.str[:-1].astype(int)\n",
    "    mask = (positions >= low) & (positions <= high)\n",
    "    return df.loc[:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_10 = filter_range_columns(onehot,low=-10,high=10)\n",
    "onehot_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6cfbe7",
   "metadata": {},
   "source": [
    "Pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31166c3b",
   "metadata": {},
   "source": [
    "```python\n",
    "onehot = onehot_encode(df_k.site_seq)\n",
    "onehot_10 = filter_range_columns(onehot)\n",
    "df_k['Cluster'] = run_kmeans(onehot_10,n=n,seed=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559cd08d",
   "metadata": {},
   "source": [
    "Then plot onehot of onehot_10 with hue ='Cluster'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333d2b2",
   "metadata": {},
   "source": [
    "### Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3cf9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_clusters_elbow(encoded_data,max_cluster=400, interval=50):\n",
    "\n",
    "    wcss = []\n",
    "    for i in range(1, max_cluster,interval):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "        kmeans.fit(encoded_data)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot the Elbow graph\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.plot(range(1, max_cluster,interval), wcss)\n",
    "    plt.title(f'Elbow Method (n={len(encoded_data)})')\n",
    "    plt.xlabel('# Clusters')\n",
    "    plt.ylabel('WCSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a017838",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clusters_elbow(onehot,5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaeeb05",
   "metadata": {},
   "source": [
    "### ESM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_esm(\n",
    "    df: pd.DataFrame, # DataFrame containing protein sequences\n",
    "    col: str, # column with amino acid sequences\n",
    "    model_name: str = \"esm2_t33_650M_UR50D\",\n",
    "    batch_size: int = 1, # Number of sequences per batch\n",
    "):\n",
    "    \"Extract ESM2 embeddings (mean pooled per sequence).\"\n",
    "\n",
    "    # model, alphabet = esm.pretrained.load_model_and_alphabet(model_name)\n",
    "    model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", model_name)\n",
    "    model = model.to(def_device)\n",
    "    model.eval()\n",
    "\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "    # Infer repr layer\n",
    "    match = re.search(r\"_t(\\d+)_\", model_name)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Cannot infer repr layer from {model_name}\")\n",
    "    layer = int(match.group(1))\n",
    "\n",
    "    print(f\"Using ESM layer {layer}\")\n",
    "    print(\"Available models:\\n\"\n",
    "          \"esm2_t48_15B_UR50D\\n\"\n",
    "          \"esm2_t36_3B_UR50D\\n\"\n",
    "          \"esm2_t33_650M_UR50D\\n\"\n",
    "          \"esm2_t30_150M_UR50D\\n\"\n",
    "          \"esm2_t12_35M_UR50D\\n\"\n",
    "          \"esm2_t6_8M_UR50D\\n\")\n",
    "\n",
    "    sequences = df[col].tolist()\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(sequences), batch_size)):\n",
    "        batch_seqs = sequences[i : i + batch_size]\n",
    "        data = [(f\"seq_{j}\", s) for j, s in enumerate(batch_seqs)]\n",
    "\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "        batch_tokens = batch_tokens.to(def_device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            results = model(batch_tokens, repr_layers=[layer], return_contacts=False)\n",
    "\n",
    "        token_reps = results[\"representations\"][layer]\n",
    "        batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "        for j, seq_len in enumerate(batch_lens):\n",
    "            # skip BOS (0), stop before EOS\n",
    "            emb = token_reps[j, 1 : seq_len - 1].mean(0)\n",
    "            all_embeddings.append(emb.cpu().numpy())\n",
    "\n",
    "        del results, token_reps, batch_tokens\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    df_emb = pd.DataFrame(\n",
    "        all_embeddings,\n",
    "        index=df.index,\n",
    "        columns=[f\"esm_{i}\" for i in range(len(all_embeddings[0]))],\n",
    "    )\n",
    "\n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a11234",
   "metadata": {},
   "source": [
    "[ESM2 model](https://github.com/facebookresearch/esm) is trained on UniRef sequence. The default model in the function is esm2_t33_650M_UR50D, which is trained  on UniRef50.\n",
    "\n",
    "Uncheck below to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Examples\n",
    "# df = Data.get_kinase_info().set_index('kinase')\n",
    "# sample = df[:5]\n",
    "# esmfeature = get_esm(sample,'sequence')\n",
    "# esmfeature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5982244",
   "metadata": {},
   "source": [
    "### ProtT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_t5(df: pd.DataFrame, \n",
    "           col: str = 'sequence'\n",
    "           ):\n",
    "    \"Extract ProtT5-XL-uniref50 embeddings from protein sequence in a dataframe\"\n",
    "    from transformers import T5Tokenizer, T5EncoderModel\n",
    "    \n",
    "    # Reference: https://github.com/agemagician/ProtTrans/tree/master/Embedding/PyTorch/Advanced\n",
    "    # Load the tokenizer\n",
    "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "\n",
    "    # Load the model\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\").to(def_device)\n",
    "\n",
    "    # Set the model precision based on the device\n",
    "    model.half()\n",
    "    \n",
    "    def T5_embeddings(sequence):\n",
    "        seq_len = len(sequence)\n",
    "        # Prepare the protein sequences as a list\n",
    "        sequence = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence)))]\n",
    "\n",
    "        # Tokenize sequences and pad up to the longest sequence in the batch\n",
    "        ids = tokenizer.batch_encode_plus(sequence, add_special_tokens=True, padding=\"longest\")\n",
    "        input_ids = torch.tensor(ids['input_ids']).to(def_device)\n",
    "        attention_mask = torch.tensor(ids['attention_mask']).to(def_device)\n",
    "        # Generate embeddings\n",
    "        with torch.no_grad():\n",
    "            embedding_rpr = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        emb_mean = embedding_rpr.last_hidden_state[0][:seq_len].detach().to(torch.float32).cpu().numpy().mean(axis=0)\n",
    "\n",
    "        return emb_mean\n",
    "\n",
    "    series = df[col].progress_apply(T5_embeddings)\n",
    "        \n",
    "\n",
    "    T5_feature = pd.DataFrame(series.tolist(),index=df.index)\n",
    "    T5_feature.columns = 'T5_' + T5_feature.columns.astype(str)\n",
    "    \n",
    "    return T5_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399d09b",
   "metadata": {},
   "source": [
    "[XL-uniref50 model](https://huggingface.co/Rostlab/prot_t5_xl_uniref50) is a t5-3b model trained on Uniref50 Dataset.\n",
    "\n",
    "Uncheck below to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f643f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5feature = get_t5(sample,'sequence')\n",
    "# t5feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_t5_bfd(df:pd.DataFrame, \n",
    "               col: str = 'sequence'\n",
    "               ):\n",
    "    \n",
    "    \"Extract ProtT5-XL-BFD embeddings from protein sequence in a dataframe\"\n",
    "    # Reference: https://github.com/agemagician/ProtTrans/tree/master/Embedding/PyTorch/Advanced\n",
    "    from transformers import T5Tokenizer, T5Model\n",
    "    # Load the tokenizer\n",
    "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_bfd', do_lower_case=False)\n",
    "\n",
    "    model = T5Model.from_pretrained(\"Rostlab/prot_t5_xl_bfd\").to(def_device)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    def T5_embeddings_bfd(sequence, device = def_device):\n",
    "        seq_len = len(sequence)\n",
    "\n",
    "        # Prepare the protein sequences as a list\n",
    "        sequence = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence)))]\n",
    "\n",
    "        # Tokenize sequences and pad up to the longest sequence in the batch\n",
    "        ids = tokenizer.batch_encode_plus(sequence, add_special_tokens=True, padding=\"longest\")\n",
    "        input_ids = torch.tensor(ids['input_ids']).to(def_device)\n",
    "        attention_mask = torch.tensor(ids['attention_mask']).to(def_device)\n",
    "\n",
    "        # Generate embeddings\n",
    "        with torch.no_grad():\n",
    "            embedding_rpr = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids = input_ids)\n",
    "\n",
    "        emb_mean = embedding_rpr.last_hidden_state[0][:seq_len].detach().to(torch.float32).cpu().numpy().mean(axis=0)\n",
    "\n",
    "        return emb_mean\n",
    "\n",
    "    series = df[col].progress_apply(T5_embeddings_bfd)\n",
    "        \n",
    "\n",
    "    T5_feature = pd.DataFrame(series.tolist(),index=df.index)\n",
    "    T5_feature.columns = 'T5bfd_' + T5_feature.columns.astype(str)\n",
    "    \n",
    "    return T5_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f292d69",
   "metadata": {},
   "source": [
    "[XL-BFD model](https://huggingface.co/Rostlab/prot_t5_xl_bfd) is a t5-3b model trained on Big Fantastic Database(BFD).\n",
    "\n",
    "Uncheck below to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5bfd = get_t5_bfd(sample,'sequence')\n",
    "# t5bfd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e44443",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802adf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
