{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML\n",
    "\n",
    "> A collection of machine learning tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import sys\n",
    "sys.path.append(\"/notebooks/katlas\")\n",
    "from nbdev.showdoc import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| output: False\n",
    "from sklearn import set_config\n",
    "from katlas.core import Data\n",
    "from katlas.feature import *\n",
    "from fastbook import *\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "from sklearn.model_selection import *\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from joblib import dump, load\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.ensemble import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_splits(df, # df contains info for split\n",
    "               stratified=None, # colname to make stratified kfold; sampling from different groups\n",
    "               group=None, # colname to make group kfold; test and train are from different groups\n",
    "               nfold=5,\n",
    "              seed=123):\n",
    "    # train_idx, test_idx = None, None\n",
    "    \n",
    "    splits = []\n",
    "    if stratified is not None and group is None:\n",
    "        kf = StratifiedKFold(nfold, shuffle=True, random_state=seed)\n",
    "        for split in kf.split(df.index, df[stratified]):\n",
    "            splits.append(split)\n",
    "        print(kf)\n",
    "        split = splits[0]\n",
    "        print(f'# kinase {stratified} in train set: {df.loc[split[0]][stratified].unique().shape[0]}')\n",
    "        print(f'# kinase {stratified} in test set: {df.loc[split[1]][stratified].unique().shape[0]}')\n",
    "        \n",
    "    elif group is not None and stratified is None:\n",
    "        kf = GroupKFold(nfold)\n",
    "        for split in kf.split(df.index, groups=df[group]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        print(kf)\n",
    "        split = splits[0]\n",
    "        print(f'# kinase {group} in train set: {df.loc[split[0]][group].unique().shape[0]}')\n",
    "        print(f'# kinase {group} in test set: {df.loc[split[1]][group].unique().shape[0]}')\n",
    "        \n",
    "    elif stratified is not None and group is not None:\n",
    "        kf = StratifiedGroupKFold(nfold, shuffle=True, random_state=seed)\n",
    "        for split in kf.split(df.index, groups=df[group], y=df[stratified]):\n",
    "            splits.append(split)\n",
    "            \n",
    "        print(kf)    \n",
    "        split = splits[0]\n",
    "        print(f'# kinase {stratified} in train set: {df.loc[split[0]][stratified].unique().shape[0]}')\n",
    "        print(f'# kinase {stratified} in test set: {df.loc[split[1]][stratified].unique().shape[0]}')\n",
    "    else:\n",
    "        raise ValueError(\"Either 'stratified' or 'group' argument must be provided.\")\n",
    "        \n",
    "        \n",
    "    print('---------------------------')\n",
    "    print(f'# kinase in train set: {df.loc[split[0]].kinase.unique().shape[0]}')\n",
    "    \n",
    "    print('---------------------------')\n",
    "    print(f'# kinase in test set: {df.loc[split[1]].kinase.unique().shape[0]}')\n",
    "    print('---------------------------')\n",
    "    print(f'test set: {df.loc[split[1]].kinase.unique()}')\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_data(df, # dataframe of values\n",
    "               feat_col, # feature columns\n",
    "               target_col, # target columns\n",
    "               split # one of the split in splits\n",
    "              ):\n",
    "    \n",
    "    X_train = df.loc[split[0]][feat_col]\n",
    "    y_train = df.loc[split[0]][target_col]\n",
    "    \n",
    "    X_test = df.loc[split[1]][feat_col]\n",
    "    y_test = df.loc[split[1]][target_col]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_ml(df, # dataframe of values\n",
    "             feat_col, # feature columns\n",
    "             target_col, # target columns\n",
    "             split, # one split in splits\n",
    "             model,  # a sklearn models\n",
    "             save = None, # file (.joblib) to save, e.g. 'model.joblib'\n",
    "             params={},\n",
    "            ):\n",
    "    \n",
    "    \" Train one split of data. Need to specify dataframe, feature columns, target columns, split, and which sklearn models to use\"\n",
    "    \n",
    "    # split data\n",
    "    X_train, y_train, X_test, y_test = split_data(df, feat_col, target_col, split)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, **params) # better convert y_train to numpy array and flatten\n",
    "    print(model)\n",
    "    \n",
    "    if save is not None:\n",
    "        # Save the model to a file\n",
    "        # joblib.dump(model, save)\n",
    "        dump(model, save)\n",
    "        \n",
    "    # Predict train\n",
    "    y_train_pred = model.predict(X_train) # X_test is dataframe, y_pred is numpy array\n",
    "    print(f'training set mse: {mean_squared_error(y_train, y_train_pred)}')\n",
    "    \n",
    "    # Predict test\n",
    "    y_pred = model.predict(X_test) # X_test is dataframe, y_pred is numpy array\n",
    "    print(f'test set mse: {mean_squared_error(y_test, y_pred)}')\n",
    "    y_pred = pd.DataFrame(y_pred,index=y_test.index, columns = y_test.columns)\n",
    "    \n",
    "    return y_test, y_pred #two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predict_ml(df, # Dataframe that contains features\n",
    "               feat_col, # feature columns\n",
    "               model_pth # models.joblib\n",
    "              ):\n",
    "    \n",
    "    test = df[feat_col]\n",
    "    \n",
    "    model = load(model_pth)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    \n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def score_all(target, pred):\n",
    "    \n",
    "    \"Calculate the overall correlation between two dataframes; need to have same index and columns\"\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    mse = mean_squared_error(target, pred)\n",
    "    # rmse = math.sqrt(mse)\n",
    "    print(f'mse is {mse:.4f}')\n",
    "\n",
    "    # Calculate the Spearman correlation coefficient\n",
    "    spearman_corr, _ = spearmanr(target.values.ravel(), pred.values.ravel())\n",
    "    print(f\"Spearman correlation coefficient: {spearman_corr:.4f}\")\n",
    "\n",
    "    # Calculate the Pearson correlation coefficient\n",
    "    pearson_corr, _ = pearsonr(target.values.ravel(), pred.values.ravel())\n",
    "    print(f\"Pearson correlation coefficient: {pearson_corr:.4f} \")\n",
    "    \n",
    "    # return mse,spearman_corr, pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_cv(df, # dataframe of values\n",
    "             feat_col, # feature columns\n",
    "             target_col,  # target columns\n",
    "             splits, # splits\n",
    "             model, # sklearn model\n",
    "             save_name = None, # model name to be saved, e.g., 'LR'\n",
    "             params = {}\n",
    "            ):\n",
    "    OOF = []\n",
    "    for fold, split in enumerate(splits):\n",
    "        print(f'------ fold: {fold} --------')\n",
    "        \n",
    "        if save_name is not None: \n",
    "            target, pred = train_ml(df, feat_col, target_col, split, model, f'models/{save_name}_{fold}.joblib',params)\n",
    "        else:\n",
    "            target, pred = train_ml(df, feat_col, target_col, split, model, params=params)\n",
    "\n",
    "        score_all(target,pred)\n",
    "        OOF.append(pred)\n",
    "        \n",
    "    oof_df = pd.concat(OOF).sort_index()\n",
    "    \n",
    "    return oof_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def score_each(target, \n",
    "               pred,\n",
    "               absolute=False, # If absolute, then will get absolute value of spearman and pearson\n",
    "              ):\n",
    "    \"Calculate spearman and pearson per row\"\n",
    "    \n",
    "    # pred.columns = target.columns\n",
    "    sp = target.corrwith(pred,axis=1,method='spearman')\n",
    "    \n",
    "    pear = target.corrwith(pred,axis=1,method='pearson')\n",
    "    \n",
    "    df = pd.DataFrame(np.stack([sp,pear]).T,columns = ['spearman','pearson'])\n",
    "    if absolute ==True:\n",
    "        df = df.apply(abs)\n",
    "        \n",
    "    print(f'average spearman for each row is {df.spearman.mean()}')\n",
    "    print(f'average pearson for each row is {df.pearson.mean()}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def xgb_trainer(df,\n",
    "                feature_col,\n",
    "                target_col,\n",
    "                test_index=None,\n",
    "                xgb_params = { \n",
    "                            'max_depth':7, #from 4 to 7\n",
    "                            'learning_rate':0.001, #from 0.001\n",
    "                            'subsample':0.8,\n",
    "                            'colsample_bytree':1, # from 0.2 to 1, because need to take all features\n",
    "                            'eval_metric':'rmse',\n",
    "                            'objective':'reg:squarederror',\n",
    "                            'tree_method':'gpu_hist',\n",
    "                            'predictor':'gpu_predictor',\n",
    "                            'random_state':123\n",
    "                        },\n",
    "                model_file='xgb_model.bin',\n",
    "                split_seed = 123, # seed of random split\n",
    "               ):\n",
    "    \n",
    "    X = df[feature_col]\n",
    "    y = df[target_col]\n",
    "    \n",
    "    print(f'xgb params is: {xgb_params}')\n",
    "    \n",
    "    if test_index is None:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=split_seed)\n",
    "    else:\n",
    "        X_train,y_train = X.loc[~X.index.isin(test_index)],y.loc[~X.index.isin(test_index)]\n",
    "        X_test, y_test = X.loc[test_index],y.loc[test_index]\n",
    "\n",
    "        \n",
    "    print(X_train.shape,y_train.shape,X_test.shape, y_test.shape)\n",
    "    print(y_test.index)\n",
    "    #prepare matrix for xgb\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test, y_test)\n",
    "    \n",
    "    model = xgb.train(xgb_params, \n",
    "            dtrain=dtrain,\n",
    "            evals=[(dtrain,'train'),(dtest,'valid')],\n",
    "            num_boost_round=9999,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,)\n",
    "    \n",
    "    # Save the model\n",
    "    path = Path(model_file)\n",
    "    \n",
    "    # Make a directory if not exists\n",
    "    path.parent.mkdir(exist_ok=True)\n",
    "        \n",
    "    model.save_model(model_file)\n",
    "    print(f'Model saved to {model_file}')\n",
    "    \n",
    "    # Prepare the pred/target df\n",
    "    pred = model.predict(dtest)\n",
    "    \n",
    "    out = np.vstack([np.ravel(y_test),np.ravel(pred)]).T\n",
    "    pred_df = pd.DataFrame(out,index=y_test.index, columns = ['target','pred'] )\n",
    "    \n",
    "    spearman_corr, _ = spearmanr(pred_df.target, pred_df.pred)\n",
    "    print(f'Spearman correlation: {spearman_corr:.2f}')\n",
    "    pearson_corr, p_value = pearsonr(pred_df.target, pred_df.pred)\n",
    "    print(f'Pearson correlation: {pearson_corr:.2f}')\n",
    "\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(pred_df.target, pred_df.pred)\n",
    "    ax.set_xlabel('True values')\n",
    "    ax.set_ylabel('Predicted values')\n",
    "    ax.set_title('Scatter plot of true versus predicted values')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    dd = model.get_score(importance_type='gain')\n",
    "    gain = pd.DataFrame({'feature':dd.keys(),f'gain_importance':dd.values()}).set_index('feature').sort_values(by='gain_importance',ascending=False)\n",
    "    gain[:10].plot.barh()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        \n",
    "    dd = model.get_score(importance_type='weight')\n",
    "    weight = pd.DataFrame({'feature':dd.keys(),f'weight_importance':dd.values()}).set_index('feature').sort_values(by='weight_importance',ascending=False)\n",
    "    weight[:10].plot.barh()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return pred_df, gain, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def xgb_predict(df, # a dataframe that contains ID and features for prediction\n",
    "                feature_col, #feature column name\n",
    "                ID_col = \"ID\", #ID column name\n",
    "                model_file='xgb_model.bin'):\n",
    "    # Load the XGBoost model\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(model_file)\n",
    "    \n",
    "    # Prepare data for prediction\n",
    "    X = df[feature_col]\n",
    "    dtest = xgb.DMatrix(X)\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = model.predict(dtest)\n",
    "    \n",
    "    # Combine predictions with IDs into a DataFrame\n",
    "    result_df = pd.DataFrame({ID_col: df[ID_col], 'preds': preds})\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
