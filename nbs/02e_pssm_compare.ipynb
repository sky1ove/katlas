{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ad3b98-74bf-4918-a0ee-baefdde19bba",
   "metadata": {},
   "source": [
    "# pssm.compare\n",
    "> algorithms about comparing two PSSMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23131f59-c7eb-4f03-a6c9-5a1235e64539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pssm.compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758d02b",
   "metadata": {},
   "source": [
    "## Overview\r\n",
    "\r\n",
    "Functions for comparing Position-Specific Scoring Matrices (PSSMs) using various divergence and similarity metrics.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**KL Divergence**\r\n",
    "\r\n",
    "`kl_divergence` computes the Kullback-Leibler divergence $D_{KL}(P \\| Q)$ between two PSSMs, measuring information lost when one distribution approximates another. Returns per-position divergence values (non-negative, 0 means identical). Note: KL divergence is **asymmetric**.\r\n",
    "\r\n",
    "```python\r\n",
    "kl_divergence(\r\n",
    "    p1=pssm_df,   # target PSSM P (DataFrame, shape: AA × positions)\r\n",
    "    p2=pssm_df2,  # predicted PSSM Q (DataFrame, same shape as p1)\r\n",
    ")\r\n",
    "```\r\n",
    "\r\n",
    "`kl_divergence_flat` computes mean KL divergence from flattened PSSM Series (e.g., rows from a PSSM DataFrame).\r\n",
    "\r\n",
    "```python\r\n",
    "kl_divergence_flat(\r\n",
    "    p1_flat=pssms.iloc[1],  # target flattened PSSM (pd.Series with 'pos_AA' index)\r\n",
    "    p2_flat=pssms.iloc[0],  # predicted flattened PSSM (pd.Series, same structure)\r\n",
    ")\r\n",
    "```\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**JS Divergence**\r\n",
    "\r\n",
    "`js_divergence` computes the Jensen-Shannon divergence, a **symmetric** version of KL divergence using the mixture $M = \\frac{1}{2}(P + Q)$. Returns per-position divergence as a Series.\r\n",
    "\r\n",
    "```python\r\n",
    "js_divergence(\r\n",
    "    p1=pssm_df,    # first PSSM (DataFrame, shape: AA × positions)\r\n",
    "    p2=pssm_df2,   # second PSSM (DataFrame, same shape)\r\n",
    "    index=True,    # whether to return Series with position index\r\n",
    ")\r\n",
    "```\r\n",
    "\r\n",
    "`js_divergence_flat` computes mean JS divergence from flattened PSSM Series.\r\n",
    "\r\n",
    "```python\r\n",
    "js_divergence_flat(\r\n",
    "    p1_flat=pssms.iloc[1],  # first flattened PSSM (pd.Series)\r\n",
    "    p2_flat=pssms.iloc[0],  # second flattened PSSM (pd.Series)\r\n",
    ")\r\n",
    "```\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**JS Similarity**\r\n",
    "\r\n",
    "`js_similarity` converts JS divergence to a similarity score in $[0, 1]$ by normalizing to bits (dividing by $\\log 2$) then computing $1 - JS_{bits}$. Returns per-position similarity.\r\n",
    "\r\n",
    "```python\r\n",
    "js_similarity(\r\n",
    "    pssm1=pssm_df,   # first PSSM (DataFrame)\r\n",
    "    pssm2=pssm_df2,  # second PSSM (DataFrame)\r\n",
    ").mean()  # average across positions\r\n",
    "```\r\n",
    "\r\n",
    "`js_similarity_flat` computes mean JS similarity from flattened PSSM Series.\r\n",
    "\r\n",
    "```python\r\n",
    "js_similarity_flat(\r\n",
    "    p1_flat=pssms.iloc[1],  # first flattened PSSM (pd.Series)\r\n",
    "    p2_flat=pssms.iloc[0],  # second flattened PSSM (pd.Series)\r\n",
    ")\r\n",
    "```\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**Cosine Similarity**\r\n",
    "\r\n",
    "`cosine_similarity` computes cosine similarity $\\frac{P \\cdot Q}{\\|P\\| \\|Q\\|}$ per position between two PSSMs. Since PSSM values are probabilities in $[0,1]$, similarity is bounded in $[0, 1]$.\r\n",
    "\r\n",
    "```python\r\n",
    "cosine_similarity(\r\n",
    "    pssm1=pssm_df,   # first PSSM (DataFrame, shape: AA × positions)\r\n",
    "    pssm2=pssm_df2,  # second PSSM (DataFrame, same shape)\r\n",
    ")\r\n",
    "```\r\n",
    "\r\n",
    "`cosine_overall_flat` computes a single overall cosine similarity across all positions from flattened PSSMs.\r\n",
    "\r\n",
    "```python\r\n",
    "cosine_overall_flat(\r\n",
    "    pssm1_flat=pssms.iloc[0],  # first flattened PSSM (pd.Series)\r\n",
    "    pssm2_flat=pssms.iloc[1],  # second flattened PSSM (pd.Series)\r\n",
    ")\r\n",
    "```\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafb610d-f059-4f21-8d41-6ce9b58fff2c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76949d54-f519-4bc6-9da5-d48a05bbfe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np, pandas as pd\r\n",
    "from katlas.pssm.core import EPSILON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae0f40-b382-4806-a4ff-a03599942733",
   "metadata": {},
   "source": [
    "## Compare PSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54457eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from katlas.data import *\n",
    "from katlas.pssm.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998b92b-1531-4b59-9328-1dde64265f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pssms = Data.get_pspa_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dabbe0-f4e5-494c-b8b5-eb71c6541896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one example\n",
    "pssm_df = recover_pssm(pssms.iloc[1])\n",
    "pssm_df2 = recover_pssm(pssms.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10e511-309d-4e98-ba14-aa1d2a4d5a5e",
   "metadata": {},
   "source": [
    "### KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef2ee7-70fd-4703-96b4-1c1a9053987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kl_divergence(p1,  # target pssm p (array-like, shape: (AA, positions))\n",
    "                  p2,  # pred pssm q (array-like, same shape as p1)\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    KL divergence D_KL(p1 || p2) over positions.\n",
    "    \n",
    "    p1 and p2 are arrays (df or np) with index as aa and column as position.\n",
    "    Returns average divergence across positions if mean=True, else per-position.\n",
    "    \"\"\"\n",
    "    assert p1.shape == p2.shape\n",
    "    p1, p2 = p1.align(p2, join='inner', axis=None)\n",
    "    # Mask invalid positions (both zero)\n",
    "    valid = (p1 + p2) > 0\n",
    "    p1 = np.where(valid, p1, 0.0)\n",
    "    p2 = np.where(valid, p2, 0.0)\n",
    "\n",
    "    # KL divergence: sum_x p1(x) log(p1(x)/p2(x))\n",
    "    kl = np.sum(p1 * np.log((p1 + EPSILON) / (p2 + EPSILON)), axis=0)\n",
    "\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003d797-a765-4eda-aacc-7854ee27ba05",
   "metadata": {},
   "source": [
    "The Kullback–Leibler (KL) divergence between two probability distributions \\( P \\) and \\( Q \\) is defined as:\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}(P \\| Q) = \\sum_{x \\in \\mathcal{X}} P(x) \\log \\left( \\frac{P(x)}{Q(x)} \\right)\n",
    "$$\n",
    "\n",
    "This measures the information lost when \\( Q \\) is used to approximate \\( P \\). It is **not symmetric**, i.e.,\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}(P \\| Q) \\ne \\mathrm{KL}(Q \\| P)\n",
    "$$\n",
    "\n",
    "and it is **non-negative**, meaning:\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}(P \\| Q) \\ge 0\n",
    "$$\n",
    "\n",
    "with equality if and only if \\( P = Q \\) almost everywhere.\n",
    "\n",
    "In practical computation, to avoid numerical instability when \\( P(x) = 0 \\) or \\( Q(x) = 0 \\), we often add a small constant \\( \\varepsilon \\):\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}_\\varepsilon(P \\| Q) = \\sum_{x \\in \\mathcal{X}} P(x) \\log \\left( \\frac{P(x) + \\varepsilon}{Q(x) + \\varepsilon} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f579e-2593-4399-987f-7df355f71fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29182172, 0.11138481, 0.24590698, 0.46021635, 0.36874823,\n",
       "       0.53858511, 1.51571614, 0.02905442, 0.08530757, 0.07753394])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(pssm_df,pssm_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d25ce-8ffa-481e-82f0-3800fad878e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.37242752573216287), np.float64(1.5157161422110503))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(pssm_df,pssm_df2).mean(),kl_divergence(pssm_df,pssm_df2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71084bb3-169a-4dc2-b5dd-1b802fda8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kl_divergence_flat(p1_flat, # pd.Series of target flattened pssm p\n",
    "                       p2_flat, # pd.Series of pred flattened pssm q\n",
    "                       ):\n",
    "\n",
    "    \"p1 and p2 are two flattened pd.Series with index as aa and column as position\"\n",
    "    kld = kl_divergence(p1_flat,p2_flat) # do not do js.mean() because it's 1d\n",
    "    total_position = len(p1_flat.index.str.extract(r'(-?\\d+)').drop_duplicates())\n",
    "    return float(kld/total_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55bb724-89fd-4a31-9eb4-942907f64e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 ms, sys: 0 ns, total: 3.03 ms\n",
      "Wall time: 3.04 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37242752573216287"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "kl_divergence_flat(pssms.iloc[1],pssms.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbe8df-919b-4437-9cfa-95101a3b52e3",
   "metadata": {},
   "source": [
    "### JS divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca99343-fbcd-48c2-a1ff-88af31fd2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def js_divergence(p1, # pssm \n",
    "                  p2, # pssm\n",
    "                  index=True,\n",
    "                 ):\n",
    "    \"p1 and p2 are two arrays (df or np) with index as aa and column as position\"\n",
    "    assert p1.shape==p2.shape\n",
    "    p1, p2 = p1.align(p2, join='inner', axis=None)\n",
    "    if index: positions=p1.columns\n",
    "    valid = (p1 + p2) > 0\n",
    "    p1 = np.where(valid, p1, 0.0)\n",
    "    p2 = np.where(valid, p2, 0.0)\n",
    "    \n",
    "    m = 0.5 * (p1 + p2)\n",
    "    \n",
    "    js = 0.5 * np.sum(p1 * np.log((p1+ EPSILON) / (m + EPSILON)), axis=0) + \\\n",
    "         0.5 * np.sum(p2 * np.log((p2+ EPSILON) / (m + EPSILON)), axis=0)\n",
    "    return pd.Series(js,index=positions) if index else js"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e461dc-6547-4b06-82ac-b2b620eed5c7",
   "metadata": {},
   "source": [
    "The Jensen-Shannon divergence between two probability distributions $P$ and $Q$ is defined as:\n",
    "\n",
    "$$\n",
    "\\mathrm{JS}(P \\| Q) = \\frac{1}{2} \\, \\mathrm{KL}(P \\| M) + \\frac{1}{2} \\, \\mathrm{KL}(Q \\| M)\n",
    "$$\n",
    "\n",
    "where $ M = \\frac{1}{2}(P + Q) $ is the average (mixture) distribution, and $ \\mathrm{KL} $ denotes the Kullback–Leibler divergence:\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}(P \\| Q) = \\sum_{x \\in \\mathcal{X}} P(x) \\log \\left( \\frac{P(x)}{Q(x)} \\right)\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\mathrm{JS}_\\varepsilon(P \\| Q) = \\frac{1}{2} \\sum_{x \\in \\mathcal{X}} P(x) \\log \\left( \\frac{P(x) + \\varepsilon}{M(x) + \\varepsilon} \\right)\n",
    "+ \\frac{1}{2} \\sum_{x \\in \\mathcal{X}} Q(x) \\log \\left( \\frac{Q(x) + \\varepsilon}{M(x) + \\varepsilon} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec512f-29f5-4a29-a222-54d865cd3bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Position\n",
       "-5    0.065539\n",
       "-4    0.025712\n",
       "-3    0.054799\n",
       "-2    0.103192\n",
       "-1    0.083377\n",
       " 0    0.105490\n",
       " 1    0.344049\n",
       " 2    0.007299\n",
       " 3    0.020949\n",
       " 4    0.018206\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_divergence(pssm_df,pssm_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb5b0ca-9327-43c0-b293-11c787c23694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.34404931056288773), np.float64(0.08286124552178498))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_divergence(pssm_df,pssm_df2).max(),js_divergence(pssm_df,pssm_df2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37553737-13b3-4461-ad93-fe4cf863f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def js_divergence_flat(p1_flat, # pd.Series of flattened pssm\n",
    "                       p2_flat, # pd.Series of flattened pssm\n",
    "                       ):\n",
    "\n",
    "    \"p1 and p2 are two flattened pd.Series with index as aa and column as position\"\n",
    "    js = js_divergence(p1_flat,p2_flat,index=False)\n",
    "    total_position = len(p1_flat.index.str.extract(r'(-?\\d+)').drop_duplicates())\n",
    "    return float(js/total_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1cb14c-053d-4879-b18c-ea1a64e8a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 ms, sys: 14 μs, total: 2.18 ms\n",
      "Wall time: 2.16 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08286124552178498"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "js_divergence_flat(pssms.iloc[1],pssms.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2716bd7a-ada5-4a3c-91da-ec544f33294a",
   "metadata": {},
   "source": [
    "### JS similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66f447-c06b-43cc-a985-97beab99903d",
   "metadata": {},
   "source": [
    "To convert the Jensen–Shannon divergence into a similarity measure, we first normalize it to bits by dividing by log(2), ensuring that the divergence lies within the range [0, 1]. \n",
    "$$\n",
    "\\mathrm{JS}_{\\text{bits}}(P \\| Q) = \\frac{\\mathrm{JS}(P \\| Q)}{\\log 2}\n",
    "$$\n",
    "\n",
    "The similarity is then defined as one minus this normalized divergence:\n",
    "$$\n",
    "\\mathrm{Sim}_{\\mathrm{JS}}(P, Q) = 1 - \\mathrm{JS}_{\\text{bits}}(P \\| Q)\n",
    "$$\n",
    "\n",
    "Thus, $\\mathrm{Sim}_{\\mathrm{JS}}$ ranges from 0 (completely dissimilar) to 1 (identical distributions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e480e54-c5de-4726-b208-c531e07a2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def js_similarity(pssm1,pssm2):\n",
    "    \"Convert JSD to bits to be in range (0,1) then 1-JSD.\"\n",
    "    distance = js_divergence(pssm1,pssm2)/np.log(2)\n",
    "    similarity = 1-distance\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d459f8-4059-4661-a8a6-bfeeb046c37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.880456492003838)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_similarity(pssm_df,pssm_df2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51e8b5-df29-431b-8013-ff46388b4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def js_similarity_flat(p1_flat,p2_flat):\n",
    "    \"Convert JSD to bits to be in range (0,1) then 1-JSD. \"\n",
    "    return 1-(js_divergence_flat(p1_flat,p2_flat)/np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba74b0-6719-41a7-bea7-46a55d9de774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.880456492003838)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_similarity_flat(pssms.iloc[1],pssms.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027def53-5ae9-4c70-b40a-36c61088b1de",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e228a-8543-4174-8c24-ce6ded317c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cosine_similarity(pssm1: pd.DataFrame, pssm2: pd.DataFrame) -> pd.Series:\n",
    "    \"Compute cosine similarity per position (column) between two PSSMs.\"\n",
    "    \n",
    "    assert pssm1.shape == pssm2.shape, \"PSSMs must have the same shape\"\n",
    "    \n",
    "    sims = {}\n",
    "    for pos in pssm1.columns:\n",
    "        v1 = pssm1[pos]\n",
    "        v2 = pssm2[pos]\n",
    "        v1,v2 = v1.align(v2, join='inner') # make sure the aa index match with each other\n",
    "\n",
    "        norm1 = np.linalg.norm(v1)\n",
    "        norm2 = np.linalg.norm(v2)\n",
    "\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            sims[pos] = 0.0\n",
    "        else:\n",
    "            dot_product = sum(v1*v2) # np.dot(v1,v2)\n",
    "            sims[pos] = dot_product / (norm1 * norm2)\n",
    "\n",
    "    return pd.Series(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26079c-cfc5-4411-a78e-c97e530aa905",
   "metadata": {},
   "source": [
    "The cosine similarity between two vectors \\( P \\) and \\( Q \\) (e.g., two PSSM columns representing amino acid probability distributions) is defined as:\n",
    "\n",
    "$$\n",
    "\\mathrm{cos}(P, Q) = \\frac{P \\cdot Q}{\\|P\\| \\, \\|Q\\|}\n",
    "$$\n",
    "\n",
    "where $ P \\cdot Q = \\sum_{i=1}^{n} P_i Q_i $ is the dot product between $ P $ and $ Q $, and $ \\|P\\| = \\sqrt{\\sum_{i=1}^{n} P_i^2} $ is the Euclidean norm of $ P $.\n",
    "\n",
    "Since all entries of $ P $ and $ Q $ are nonnegative probabilities (i.e., $ P_i, Q_i \\in [0,1] $), the cosine similarity lies within the range:\n",
    "\n",
    "$$\n",
    "0 \\leq \\mathrm{cos}(P, Q) \\leq 1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b2d57-17f2-4639-91d9-1d05608d0fda",
   "metadata": {},
   "source": [
    "Given that pssm are probabilities between 0 and 1, cosine similarity is within (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148694c5-d1a3-404c-85de-50f54c8ae0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.130818\n",
       "-2    0.606234\n",
       "-1    0.731466\n",
       " 0    0.780066\n",
       "-5    0.780504\n",
       "-3    0.786276\n",
       "-4    0.901395\n",
       " 3    0.918692\n",
       " 4    0.934967\n",
       " 2    0.971066\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(pssm_df,pssm_df2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd196a45-4ada-459d-86a2-88b12679914c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7541484704577781)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(pssm_df,pssm_df2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830fbaa-4a9f-4d5d-98ba-289fc91bff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cosine_overall_flat(pssm1_flat, pssm2_flat):\n",
    "    \"\"\"Compute overall cosine similarity between two PSSMs (flattened).\"\"\"\n",
    "    # match index for dot product\n",
    "    pssm1_flat, pssm2_flat = pssm1_flat.align(pssm2_flat, join='inner')\n",
    "    norm1 = np.linalg.norm(pssm1_flat)\n",
    "    norm2 = np.linalg.norm(pssm2_flat)\n",
    "    if norm1 == 0 or norm2 == 0: return 0.0\n",
    "    dot_product = sum(pssm1_flat*pssm2_flat) # np.dot(pssm1_flat, pssm2_flat)\n",
    "    return  dot_product/ (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9463baf-aec2-4ef7-8629-e43b946b6325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9999999999999999)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_overall_flat(pssms.iloc[0],pssms.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c045e7-b3d8-430e-9afb-8134a3b02f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6614783212500968)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_overall_flat(pssms.iloc[0],pssms.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495586d-9089-4cec-9e71-f279cd20124b",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2e9b8-8ac2-4110-92db-c0100b43de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
